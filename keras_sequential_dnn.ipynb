{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Values in Suburbs of Boston\n",
    "\n",
    "The Boston data frame has 506 rows and 14 columns. This data frame contains the following columns:\n",
    "\n",
    "<li> crim - per capita crime rate by town.\n",
    "<li> zn - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "<li> indus - proportion of non-retail business acres per town.\n",
    "<li> chas - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "<li> nox - nitrogen oxides concentration (parts per 10 million).\n",
    "<li> rm - average number of rooms per dwelling.\n",
    "<li> age - proportion of owner-occupied units built prior to 1940.\n",
    "<li> dis - weighted mean of distances to five Boston employment centres.\n",
    "<li> rad - index of accessibility to radial highways.\n",
    "<li> tax - full-value property-tax rate per 10,000 dollars.\n",
    "<li> ptratio - pupil-teacher ratio by town.\n",
    "<li> black - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "<li> lstat - lower status of the population (percent).\n",
    "<li> medv - median value of owner-occupied homes in 1000s (dollar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc; gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variables\n",
    "learning_rate = 0.01\n",
    "epochs_value = 100\n",
    "batch_size_value = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define features and label\n",
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 123; \n",
    "np.random.seed(seed); \n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (506, 14) \n",
      "\n",
      "Data types: \n",
      " crim       float64\n",
      "zn         float64\n",
      "indus      float64\n",
      "chas         int64\n",
      "nox        float64\n",
      "rm         float64\n",
      "age        float64\n",
      "dis        float64\n",
      "rad          int64\n",
      "tax          int64\n",
      "ptratio    float64\n",
      "black      float64\n",
      "lstat      float64\n",
      "medv       float64\n",
      "dtype: object \n",
      "\n",
      "Data head: \n",
      "       crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "    black  lstat  medv  \n",
      "0  396.90   4.98  24.0  \n",
      "1  396.90   9.14  21.6  \n",
      "2  392.83   4.03  34.7  \n",
      "3  394.63   2.94  33.4  \n",
      "4  396.90   5.33  36.2   \n",
      "\n",
      "Describe data: \n",
      "              crim          zn       indus        chas         nox          rm  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              age         dis         rad         tax     ptratio       black  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            lstat        medv  \n",
      "count  506.000000  506.000000  \n",
      "mean    12.653063   22.532806  \n",
      "std      7.141062    9.197104  \n",
      "min      1.730000    5.000000  \n",
      "25%      6.950000   17.025000  \n",
      "50%     11.360000   21.200000  \n",
      "75%     16.955000   25.000000  \n",
      "max     37.970000   50.000000  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data = pd.read_csv(\"Boston.csv\")\n",
    "\n",
    "#general info\n",
    "print('Data shape:',data.shape,'\\n')\n",
    "print('Data types:','\\n',data.dtypes,'\\n')\n",
    "print('Data head:','\\n',data.head(5),'\\n')\n",
    "print('Describe data:','\\n',data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Split 85% and 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "training_set ,test_set = train_test_split(data,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10,  input_shape=(len(FEATURES),), activation=\"sigmoid\", \n",
    "                                kernel_initializer = tf.random_normal_initializer))\n",
    "model.add(tf.keras.layers.Dense(1,kernel_initializer = tf.random_normal_initializer)) \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0883334   1.6099403  -1.2420341  -0.57991624  0.9011749  -0.5680958\n",
      "   0.11468925  0.7251606   1.0741915   0.9523627 ]\n",
      " [ 0.63224566 -0.4683439   0.39733338 -0.5503299  -1.3921223  -1.3164045\n",
      "   2.0284896   1.2268329  -0.6456442  -0.70995665]\n",
      " [ 0.97266996  0.37199238  1.7680062   0.3652682  -0.16087858  0.35340807\n",
      "   0.40600118 -0.03091604  0.10590505 -0.41147006]\n",
      " [-0.25397405  0.22934902 -0.6301569  -0.68323857  0.01871364 -1.1076498\n",
      "  -0.06042137 -0.3668015  -1.5964891   0.20743962]\n",
      " [ 1.180202   -1.3911604   0.5283256  -1.1360271   0.13856302 -0.06989487\n",
      "   1.1038681   2.3240397   1.6409857   0.8848552 ]\n",
      " [-0.28269017  1.376043    1.8257636   0.03662585 -0.03508681 -0.3455922\n",
      "   1.287203   -1.1046579   0.05076596 -0.10048706]\n",
      " [ 0.5440388   0.47445366 -1.3354398   0.23849551 -0.28112656 -0.6153317\n",
      "  -1.2543718   0.12354399  0.1537378   1.4873191 ]\n",
      " [ 0.64532286  0.88492787  0.773822    0.08391538 -0.11384094  1.0435164\n",
      "   1.1663067  -0.76029325 -0.94744635  0.8794718 ]\n",
      " [ 0.04892648 -1.3134118  -1.4756519   1.4538163   0.18569939 -0.28042316\n",
      "   0.33337554  0.0551138  -1.3361831  -0.6375603 ]] \n",
      "\n",
      "(9, 10)\n"
     ]
    }
   ],
   "source": [
    "#get weights [0], get bias [1]\n",
    "layer_input = model.layers[0]\n",
    "print(layer_input.get_weights()[0],'\\n')\n",
    "print(layer_input.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model, get metrics\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "430/430 [==============================] - 0s 747us/step - loss: 753.3672 - mean_squared_error: 753.3672 - val_loss: 814.7752 - val_mean_squared_error: 814.7752\n",
      "Epoch 2/100\n",
      "430/430 [==============================] - 0s 113us/step - loss: 731.7606 - mean_squared_error: 731.7606 - val_loss: 792.4976 - val_mean_squared_error: 792.4976\n",
      "Epoch 3/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 710.6150 - mean_squared_error: 710.6150 - val_loss: 770.5269 - val_mean_squared_error: 770.5269\n",
      "Epoch 4/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 690.0186 - mean_squared_error: 690.0186 - val_loss: 749.1106 - val_mean_squared_error: 749.1106\n",
      "Epoch 5/100\n",
      "430/430 [==============================] - 0s 126us/step - loss: 669.9054 - mean_squared_error: 669.9054 - val_loss: 728.3955 - val_mean_squared_error: 728.3955\n",
      "Epoch 6/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 650.1623 - mean_squared_error: 650.1623 - val_loss: 707.6504 - val_mean_squared_error: 707.6504\n",
      "Epoch 7/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 630.5371 - mean_squared_error: 630.5371 - val_loss: 687.4134 - val_mean_squared_error: 687.4134\n",
      "Epoch 8/100\n",
      "430/430 [==============================] - 0s 145us/step - loss: 611.5385 - mean_squared_error: 611.5385 - val_loss: 667.5602 - val_mean_squared_error: 667.5602\n",
      "Epoch 9/100\n",
      "430/430 [==============================] - 0s 118us/step - loss: 592.8836 - mean_squared_error: 592.8836 - val_loss: 648.3006 - val_mean_squared_error: 648.3006\n",
      "Epoch 10/100\n",
      "430/430 [==============================] - 0s 125us/step - loss: 574.7871 - mean_squared_error: 574.7871 - val_loss: 629.7153 - val_mean_squared_error: 629.7153\n",
      "Epoch 11/100\n",
      "430/430 [==============================] - 0s 108us/step - loss: 557.2570 - mean_squared_error: 557.2570 - val_loss: 611.3441 - val_mean_squared_error: 611.3441\n",
      "Epoch 12/100\n",
      "430/430 [==============================] - 0s 108us/step - loss: 540.2200 - mean_squared_error: 540.2200 - val_loss: 593.4643 - val_mean_squared_error: 593.4643\n",
      "Epoch 13/100\n",
      "430/430 [==============================] - 0s 109us/step - loss: 523.6100 - mean_squared_error: 523.6100 - val_loss: 576.2296 - val_mean_squared_error: 576.2296\n",
      "Epoch 14/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 507.4484 - mean_squared_error: 507.4484 - val_loss: 559.6060 - val_mean_squared_error: 559.6060\n",
      "Epoch 15/100\n",
      "430/430 [==============================] - 0s 107us/step - loss: 491.8015 - mean_squared_error: 491.8015 - val_loss: 543.1333 - val_mean_squared_error: 543.1333\n",
      "Epoch 16/100\n",
      "430/430 [==============================] - 0s 106us/step - loss: 476.5348 - mean_squared_error: 476.5348 - val_loss: 527.1417 - val_mean_squared_error: 527.1417\n",
      "Epoch 17/100\n",
      "430/430 [==============================] - 0s 115us/step - loss: 461.6762 - mean_squared_error: 461.6762 - val_loss: 511.6682 - val_mean_squared_error: 511.6682\n",
      "Epoch 18/100\n",
      "430/430 [==============================] - 0s 107us/step - loss: 447.2714 - mean_squared_error: 447.2714 - val_loss: 496.5706 - val_mean_squared_error: 496.5706\n",
      "Epoch 19/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 433.2322 - mean_squared_error: 433.2322 - val_loss: 481.8695 - val_mean_squared_error: 481.8695\n",
      "Epoch 20/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 419.5803 - mean_squared_error: 419.5803 - val_loss: 467.6723 - val_mean_squared_error: 467.6723\n",
      "Epoch 21/100\n",
      "430/430 [==============================] - 0s 110us/step - loss: 406.3753 - mean_squared_error: 406.3753 - val_loss: 453.6161 - val_mean_squared_error: 453.6161\n",
      "Epoch 22/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 393.4719 - mean_squared_error: 393.4719 - val_loss: 440.0977 - val_mean_squared_error: 440.0977\n",
      "Epoch 23/100\n",
      "430/430 [==============================] - 0s 115us/step - loss: 380.9770 - mean_squared_error: 380.9770 - val_loss: 426.9210 - val_mean_squared_error: 426.9210\n",
      "Epoch 24/100\n",
      "430/430 [==============================] - 0s 99us/step - loss: 368.8222 - mean_squared_error: 368.8222 - val_loss: 414.2737 - val_mean_squared_error: 414.2737\n",
      "Epoch 25/100\n",
      "430/430 [==============================] - 0s 150us/step - loss: 357.0699 - mean_squared_error: 357.0699 - val_loss: 401.7824 - val_mean_squared_error: 401.7824\n",
      "Epoch 26/100\n",
      "430/430 [==============================] - 0s 154us/step - loss: 345.6214 - mean_squared_error: 345.6214 - val_loss: 389.7899 - val_mean_squared_error: 389.7899\n",
      "Epoch 27/100\n",
      "430/430 [==============================] - 0s 166us/step - loss: 334.5471 - mean_squared_error: 334.5471 - val_loss: 378.0864 - val_mean_squared_error: 378.0864\n",
      "Epoch 28/100\n",
      "430/430 [==============================] - 0s 161us/step - loss: 323.8371 - mean_squared_error: 323.8371 - val_loss: 366.5444 - val_mean_squared_error: 366.5444\n",
      "Epoch 29/100\n",
      "430/430 [==============================] - 0s 168us/step - loss: 313.4027 - mean_squared_error: 313.4027 - val_loss: 355.5498 - val_mean_squared_error: 355.5498\n",
      "Epoch 30/100\n",
      "430/430 [==============================] - 0s 172us/step - loss: 303.3038 - mean_squared_error: 303.3038 - val_loss: 344.9944 - val_mean_squared_error: 344.9944\n",
      "Epoch 31/100\n",
      "430/430 [==============================] - 0s 162us/step - loss: 293.5802 - mean_squared_error: 293.5802 - val_loss: 334.4622 - val_mean_squared_error: 334.4622\n",
      "Epoch 32/100\n",
      "430/430 [==============================] - 0s 182us/step - loss: 284.1152 - mean_squared_error: 284.1152 - val_loss: 324.4159 - val_mean_squared_error: 324.4159\n",
      "Epoch 33/100\n",
      "430/430 [==============================] - 0s 167us/step - loss: 274.9756 - mean_squared_error: 274.9756 - val_loss: 314.6553 - val_mean_squared_error: 314.6553\n",
      "Epoch 34/100\n",
      "430/430 [==============================] - 0s 122us/step - loss: 266.1585 - mean_squared_error: 266.1585 - val_loss: 305.1656 - val_mean_squared_error: 305.1656\n",
      "Epoch 35/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 257.5818 - mean_squared_error: 257.5818 - val_loss: 296.0928 - val_mean_squared_error: 296.0928\n",
      "Epoch 36/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 249.3328 - mean_squared_error: 249.3328 - val_loss: 287.2268 - val_mean_squared_error: 287.2268\n",
      "Epoch 37/100\n",
      "430/430 [==============================] - 0s 150us/step - loss: 241.3305 - mean_squared_error: 241.3305 - val_loss: 278.7460 - val_mean_squared_error: 278.7460\n",
      "Epoch 38/100\n",
      "430/430 [==============================] - 0s 125us/step - loss: 233.6359 - mean_squared_error: 233.6359 - val_loss: 270.4172 - val_mean_squared_error: 270.4172\n",
      "Epoch 39/100\n",
      "430/430 [==============================] - 0s 135us/step - loss: 226.1858 - mean_squared_error: 226.1858 - val_loss: 262.3803 - val_mean_squared_error: 262.3803\n",
      "Epoch 40/100\n",
      "430/430 [==============================] - 0s 158us/step - loss: 219.0008 - mean_squared_error: 219.0008 - val_loss: 254.5904 - val_mean_squared_error: 254.5904\n",
      "Epoch 41/100\n",
      "430/430 [==============================] - 0s 172us/step - loss: 212.0863 - mean_squared_error: 212.0863 - val_loss: 247.0674 - val_mean_squared_error: 247.0674\n",
      "Epoch 42/100\n",
      "430/430 [==============================] - 0s 117us/step - loss: 205.4403 - mean_squared_error: 205.4403 - val_loss: 239.8644 - val_mean_squared_error: 239.8644\n",
      "Epoch 43/100\n",
      "430/430 [==============================] - 0s 105us/step - loss: 199.0234 - mean_squared_error: 199.0234 - val_loss: 232.9951 - val_mean_squared_error: 232.9951\n",
      "Epoch 44/100\n",
      "430/430 [==============================] - 0s 109us/step - loss: 192.8844 - mean_squared_error: 192.8844 - val_loss: 226.2177 - val_mean_squared_error: 226.2177\n",
      "Epoch 45/100\n",
      "430/430 [==============================] - 0s 110us/step - loss: 186.9383 - mean_squared_error: 186.9383 - val_loss: 219.7525 - val_mean_squared_error: 219.7525\n",
      "Epoch 46/100\n",
      "430/430 [==============================] - 0s 120us/step - loss: 181.2169 - mean_squared_error: 181.2169 - val_loss: 213.5503 - val_mean_squared_error: 213.5503\n",
      "Epoch 47/100\n",
      "430/430 [==============================] - 0s 105us/step - loss: 175.7782 - mean_squared_error: 175.7782 - val_loss: 207.3534 - val_mean_squared_error: 207.3534\n",
      "Epoch 48/100\n",
      "430/430 [==============================] - 0s 104us/step - loss: 170.4898 - mean_squared_error: 170.4898 - val_loss: 201.6518 - val_mean_squared_error: 201.6518\n",
      "Epoch 49/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 165.5084 - mean_squared_error: 165.5084 - val_loss: 196.0005 - val_mean_squared_error: 196.0005\n",
      "Epoch 50/100\n",
      "430/430 [==============================] - 0s 108us/step - loss: 160.6666 - mean_squared_error: 160.6666 - val_loss: 190.7312 - val_mean_squared_error: 190.7312\n",
      "Epoch 51/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 156.0412 - mean_squared_error: 156.0412 - val_loss: 185.7485 - val_mean_squared_error: 185.7485\n",
      "Epoch 52/100\n",
      "430/430 [==============================] - 0s 129us/step - loss: 151.6396 - mean_squared_error: 151.6396 - val_loss: 180.8823 - val_mean_squared_error: 180.8823\n",
      "Epoch 53/100\n",
      "430/430 [==============================] - 0s 107us/step - loss: 147.4409 - mean_squared_error: 147.4409 - val_loss: 176.0059 - val_mean_squared_error: 176.0059\n",
      "Epoch 54/100\n",
      "430/430 [==============================] - 0s 100us/step - loss: 143.3908 - mean_squared_error: 143.3908 - val_loss: 171.4732 - val_mean_squared_error: 171.4732\n",
      "Epoch 55/100\n",
      "430/430 [==============================] - 0s 107us/step - loss: 139.5442 - mean_squared_error: 139.5442 - val_loss: 167.0709 - val_mean_squared_error: 167.0709\n",
      "Epoch 56/100\n",
      "430/430 [==============================] - 0s 100us/step - loss: 135.8687 - mean_squared_error: 135.8687 - val_loss: 162.9498 - val_mean_squared_error: 162.9498\n",
      "Epoch 57/100\n",
      "430/430 [==============================] - 0s 100us/step - loss: 132.4050 - mean_squared_error: 132.4050 - val_loss: 158.9842 - val_mean_squared_error: 158.9842\n",
      "Epoch 58/100\n",
      "430/430 [==============================] - 0s 106us/step - loss: 129.0903 - mean_squared_error: 129.0903 - val_loss: 155.2319 - val_mean_squared_error: 155.2319\n",
      "Epoch 59/100\n",
      "430/430 [==============================] - 0s 105us/step - loss: 125.9403 - mean_squared_error: 125.9403 - val_loss: 151.6413 - val_mean_squared_error: 151.6413\n",
      "Epoch 60/100\n",
      "430/430 [==============================] - 0s 104us/step - loss: 122.9601 - mean_squared_error: 122.9601 - val_loss: 148.1302 - val_mean_squared_error: 148.1302\n",
      "Epoch 61/100\n",
      "430/430 [==============================] - 0s 106us/step - loss: 120.1016 - mean_squared_error: 120.1016 - val_loss: 145.0115 - val_mean_squared_error: 145.0115\n",
      "Epoch 62/100\n",
      "430/430 [==============================] - 0s 100us/step - loss: 117.4638 - mean_squared_error: 117.4638 - val_loss: 141.7528 - val_mean_squared_error: 141.7528\n",
      "Epoch 63/100\n",
      "430/430 [==============================] - 0s 105us/step - loss: 114.8988 - mean_squared_error: 114.8988 - val_loss: 138.8037 - val_mean_squared_error: 138.8037\n",
      "Epoch 64/100\n",
      "430/430 [==============================] - 0s 109us/step - loss: 112.5262 - mean_squared_error: 112.5262 - val_loss: 135.9142 - val_mean_squared_error: 135.9142\n",
      "Epoch 65/100\n",
      "430/430 [==============================] - 0s 108us/step - loss: 110.2540 - mean_squared_error: 110.2540 - val_loss: 133.2455 - val_mean_squared_error: 133.2455\n",
      "Epoch 66/100\n",
      "430/430 [==============================] - 0s 109us/step - loss: 108.1374 - mean_squared_error: 108.1374 - val_loss: 130.7092 - val_mean_squared_error: 130.7092\n",
      "Epoch 67/100\n",
      "430/430 [==============================] - 0s 110us/step - loss: 106.1431 - mean_squared_error: 106.1431 - val_loss: 128.3096 - val_mean_squared_error: 128.3096\n",
      "Epoch 68/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 104.2638 - mean_squared_error: 104.2638 - val_loss: 126.0616 - val_mean_squared_error: 126.0616\n",
      "Epoch 69/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 102.5037 - mean_squared_error: 102.5037 - val_loss: 123.9874 - val_mean_squared_error: 123.9874\n",
      "Epoch 70/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 100.8856 - mean_squared_error: 100.8856 - val_loss: 121.8815 - val_mean_squared_error: 121.8815\n",
      "Epoch 71/100\n",
      "430/430 [==============================] - 0s 115us/step - loss: 99.3291 - mean_squared_error: 99.3291 - val_loss: 119.9823 - val_mean_squared_error: 119.9823\n",
      "Epoch 72/100\n",
      "430/430 [==============================] - 0s 104us/step - loss: 97.8914 - mean_squared_error: 97.8914 - val_loss: 118.1481 - val_mean_squared_error: 118.1481\n",
      "Epoch 73/100\n",
      "430/430 [==============================] - 0s 115us/step - loss: 96.5410 - mean_squared_error: 96.5410 - val_loss: 116.4861 - val_mean_squared_error: 116.4861\n",
      "Epoch 74/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 95.2969 - mean_squared_error: 95.2969 - val_loss: 114.8936 - val_mean_squared_error: 114.8936\n",
      "Epoch 75/100\n",
      "430/430 [==============================] - 0s 121us/step - loss: 94.1363 - mean_squared_error: 94.1363 - val_loss: 113.4139 - val_mean_squared_error: 113.4139\n",
      "Epoch 76/100\n",
      "430/430 [==============================] - 0s 121us/step - loss: 93.0494 - mean_squared_error: 93.0494 - val_loss: 112.0339 - val_mean_squared_error: 112.0339\n",
      "Epoch 77/100\n",
      "430/430 [==============================] - 0s 113us/step - loss: 92.0678 - mean_squared_error: 92.0678 - val_loss: 110.6886 - val_mean_squared_error: 110.6886\n",
      "Epoch 78/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 91.1423 - mean_squared_error: 91.1423 - val_loss: 109.4239 - val_mean_squared_error: 109.4239\n",
      "Epoch 79/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 90.2928 - mean_squared_error: 90.2928 - val_loss: 108.3007 - val_mean_squared_error: 108.3007\n",
      "Epoch 80/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 89.5208 - mean_squared_error: 89.5208 - val_loss: 107.2026 - val_mean_squared_error: 107.2026\n",
      "Epoch 81/100\n",
      "430/430 [==============================] - 0s 136us/step - loss: 88.8299 - mean_squared_error: 88.8299 - val_loss: 106.1582 - val_mean_squared_error: 106.1582\n",
      "Epoch 82/100\n",
      "430/430 [==============================] - 0s 145us/step - loss: 88.1650 - mean_squared_error: 88.1650 - val_loss: 105.2828 - val_mean_squared_error: 105.2828\n",
      "Epoch 83/100\n",
      "430/430 [==============================] - 0s 151us/step - loss: 87.5773 - mean_squared_error: 87.5773 - val_loss: 104.4548 - val_mean_squared_error: 104.4548\n",
      "Epoch 84/100\n",
      "430/430 [==============================] - 0s 145us/step - loss: 87.0412 - mean_squared_error: 87.0412 - val_loss: 103.6527 - val_mean_squared_error: 103.6527\n",
      "Epoch 85/100\n",
      "430/430 [==============================] - 0s 139us/step - loss: 86.5595 - mean_squared_error: 86.5595 - val_loss: 102.9015 - val_mean_squared_error: 102.9015\n",
      "Epoch 86/100\n",
      "430/430 [==============================] - 0s 143us/step - loss: 86.1079 - mean_squared_error: 86.1079 - val_loss: 102.1940 - val_mean_squared_error: 102.1940\n",
      "Epoch 87/100\n",
      "430/430 [==============================] - 0s 135us/step - loss: 85.7015 - mean_squared_error: 85.7015 - val_loss: 101.6032 - val_mean_squared_error: 101.6032\n",
      "Epoch 88/100\n",
      "430/430 [==============================] - 0s 128us/step - loss: 85.3322 - mean_squared_error: 85.3322 - val_loss: 101.0284 - val_mean_squared_error: 101.0284\n",
      "Epoch 89/100\n",
      "430/430 [==============================] - 0s 148us/step - loss: 85.0048 - mean_squared_error: 85.0048 - val_loss: 100.4408 - val_mean_squared_error: 100.4408\n",
      "Epoch 90/100\n",
      "430/430 [==============================] - 0s 132us/step - loss: 84.7002 - mean_squared_error: 84.7002 - val_loss: 99.9859 - val_mean_squared_error: 99.9859\n",
      "Epoch 91/100\n",
      "430/430 [==============================] - 0s 138us/step - loss: 84.4367 - mean_squared_error: 84.4367 - val_loss: 99.4704 - val_mean_squared_error: 99.4704\n",
      "Epoch 92/100\n",
      "430/430 [==============================] - 0s 125us/step - loss: 84.1962 - mean_squared_error: 84.1962 - val_loss: 99.0809 - val_mean_squared_error: 99.0809\n",
      "Epoch 93/100\n",
      "430/430 [==============================] - 0s 134us/step - loss: 83.9993 - mean_squared_error: 83.9993 - val_loss: 98.6160 - val_mean_squared_error: 98.6160\n",
      "Epoch 94/100\n",
      "430/430 [==============================] - 0s 129us/step - loss: 83.8051 - mean_squared_error: 83.8051 - val_loss: 98.3031 - val_mean_squared_error: 98.3031\n",
      "Epoch 95/100\n",
      "430/430 [==============================] - 0s 146us/step - loss: 83.6527 - mean_squared_error: 83.6527 - val_loss: 97.9483 - val_mean_squared_error: 97.9483\n",
      "Epoch 96/100\n",
      "430/430 [==============================] - 0s 146us/step - loss: 83.4880 - mean_squared_error: 83.4880 - val_loss: 97.5259 - val_mean_squared_error: 97.5259\n",
      "Epoch 97/100\n",
      "430/430 [==============================] - 0s 126us/step - loss: 83.0579 - mean_squared_error: 83.0579 - val_loss: 97.2905 - val_mean_squared_error: 97.2905\n",
      "Epoch 98/100\n",
      "430/430 [==============================] - 0s 131us/step - loss: 82.7723 - mean_squared_error: 82.7723 - val_loss: 96.9223 - val_mean_squared_error: 96.9223\n",
      "Epoch 99/100\n",
      "430/430 [==============================] - 0s 130us/step - loss: 82.5417 - mean_squared_error: 82.5417 - val_loss: 96.5763 - val_mean_squared_error: 96.5763\n",
      "Epoch 100/100\n",
      "430/430 [==============================] - 0s 141us/step - loss: 82.3472 - mean_squared_error: 82.3472 - val_loss: 96.3133 - val_mean_squared_error: 96.3133\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "training_model = model.fit(training_set[FEATURES].values, \n",
    "          training_set[LABEL].values, \n",
    "          epochs=epochs_value,\n",
    "          batch_size=batch_size_value,\n",
    "          validation_data=(test_set[FEATURES].values, test_set[LABEL].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB3ozs5JzoDczKzkHejOzknOgNzMruf8PpcZBp8ae1HEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot mse (metric defined in compile step)\n",
    "plt.plot(training_model.history['mean_squared_error'][-50:], 'r+', label='training mean_squared_error')\n",
    "plt.plot(training_model.history['val_mean_squared_error'][-50:], 'y.', label='evaluation mean_squared_error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Mean Squared Error over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 54us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[96.31326585066945, 96.31326585066945]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate: Returns the loss value & metrics values for the model in test mode (keras documentation) \n",
    "model.evaluate(test_set[FEATURES].values, test_set[LABEL].values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict: Generates output predictions for the input samples (keras documentation)\n",
    "predictions = model.predict(x=test_set[FEATURES].values) #, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  9.813932048683899\n"
     ]
    }
   ],
   "source": [
    "#get root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(test_set[LABEL].values, predictions))\n",
    "print(\"RMSE: \", rmse) # 9.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: re-train the model by using the following DNN topology (adding a new layer with 100 nodes).\n",
    "### A) Plot \"mean squared error\" for the new DNN topology and compare the result with the initial DNN network. ### B) Calcuate the number of new parameters. \n",
    "### C) What is the impact on \"mean squared error\" when using a larger network topology? why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train new model with additional 100 node layer\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10,  input_shape=(len(FEATURES),), activation=\"relu\", \n",
    "                                kernel_initializer = tf.random_normal_initializer))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer = tf.random_normal_initializer))\n",
    "model.add(tf.keras.layers.Dense(1,kernel_initializer = tf.random_normal_initializer)) \n",
    "print(model.summary())\n",
    "\n",
    "#original model for reference\n",
    "#model = tf.keras.Sequential()\n",
    "#model.add(tf.keras.layers.Dense(10,  input_shape=(len(FEATURES),), activation=\"sigmoid\", \n",
    "#                                kernel_initializer = tf.random_normal_initializer))\n",
    "#model.add(tf.keras.layers.Dense(1,kernel_initializer = tf.random_normal_initializer)) \n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60878754 -1.1110989   2.5595737  -1.3319879  -0.38640565  0.54587007\n",
      "   0.4752836   0.10964312 -0.17647052  0.10908844]\n",
      " [ 0.01554235 -1.7999388   0.8662198  -0.3507296  -1.014258   -0.57960016\n",
      "  -0.56619275  1.6857933  -1.4156207  -0.55981576]\n",
      " [ 0.95472634 -0.10915111  2.1123896  -1.1042067  -0.12507355  0.09118359\n",
      "  -0.67283314  0.91197735  0.6241279  -1.3470067 ]\n",
      " [-0.19839855 -1.0865504  -1.5947303   0.7800112  -0.06819467  0.29791212\n",
      "   2.050605    0.08513489 -0.3811718  -1.2553935 ]\n",
      " [ 1.8793114  -1.8072705   0.06225457  0.6152995  -0.94277465 -1.3940856\n",
      "   0.60151744 -0.43736613  0.34349146  0.77824396]\n",
      " [-1.2857434   1.4127128   0.08853617  0.6358987   0.8312282  -0.12897049\n",
      "   0.29661188  0.50105214  0.04071983 -0.26258653]\n",
      " [-1.2245747  -0.75547004  1.3012805  -1.5054928   1.2196999  -0.10124624\n",
      "   0.63518786 -0.44737175  0.94537646  0.53591126]\n",
      " [ 0.00498198 -0.25785452 -1.3921765  -1.095456    1.2865021  -0.1091504\n",
      "  -1.762889   -2.1379344   0.5495012  -0.6437378 ]\n",
      " [ 2.3080702   1.274464    1.5573074  -0.7380737  -0.71666896  0.90897775\n",
      "   0.12317938 -0.55021936 -0.9481528  -1.6999007 ]] \n",
      "\n",
      "(9, 10)\n"
     ]
    }
   ],
   "source": [
    "#get weights\n",
    "layer_input = model.layers[0]\n",
    "print(layer_input.get_weights()[0],'\\n')\n",
    "print(layer_input.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model, get metrics\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "430/430 [==============================] - 0s 692us/step - loss: 360822.8633 - mean_squared_error: 360822.8633 - val_loss: 61055.0021 - val_mean_squared_error: 61055.0021\n",
      "Epoch 2/100\n",
      "430/430 [==============================] - 0s 182us/step - loss: 51797.4219 - mean_squared_error: 51797.4219 - val_loss: 42045.7084 - val_mean_squared_error: 42045.7084\n",
      "Epoch 3/100\n",
      "430/430 [==============================] - 0s 152us/step - loss: 38509.0367 - mean_squared_error: 38509.0367 - val_loss: 31328.8224 - val_mean_squared_error: 31328.8224\n",
      "Epoch 4/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 29472.8126 - mean_squared_error: 29472.8126 - val_loss: 24440.5687 - val_mean_squared_error: 24440.5687\n",
      "Epoch 5/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 21657.4742 - mean_squared_error: 21657.4742 - val_loss: 16398.5612 - val_mean_squared_error: 16398.5612\n",
      "Epoch 6/100\n",
      "430/430 [==============================] - 0s 124us/step - loss: 15315.0393 - mean_squared_error: 15315.0393 - val_loss: 13184.4693 - val_mean_squared_error: 13184.4693\n",
      "Epoch 7/100\n",
      "430/430 [==============================] - 0s 124us/step - loss: 12543.7534 - mean_squared_error: 12543.7534 - val_loss: 10785.7194 - val_mean_squared_error: 10785.7194\n",
      "Epoch 8/100\n",
      "430/430 [==============================] - 0s 149us/step - loss: 10419.6863 - mean_squared_error: 10419.6863 - val_loss: 9014.6645 - val_mean_squared_error: 9014.6645\n",
      "Epoch 9/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 8666.5013 - mean_squared_error: 8666.5013 - val_loss: 7497.5753 - val_mean_squared_error: 7497.5753\n",
      "Epoch 10/100\n",
      "430/430 [==============================] - 0s 129us/step - loss: 7308.6249 - mean_squared_error: 7308.6249 - val_loss: 6230.9747 - val_mean_squared_error: 6230.9747\n",
      "Epoch 11/100\n",
      "430/430 [==============================] - 0s 122us/step - loss: 6052.9363 - mean_squared_error: 6052.9363 - val_loss: 5406.7475 - val_mean_squared_error: 5406.7475\n",
      "Epoch 12/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 5045.9733 - mean_squared_error: 5045.9733 - val_loss: 4086.8096 - val_mean_squared_error: 4086.8096\n",
      "Epoch 13/100\n",
      "430/430 [==============================] - 0s 124us/step - loss: 3928.9727 - mean_squared_error: 3928.9727 - val_loss: 3218.1430 - val_mean_squared_error: 3218.1430\n",
      "Epoch 14/100\n",
      "430/430 [==============================] - 0s 127us/step - loss: 3148.2293 - mean_squared_error: 3148.2293 - val_loss: 2585.0989 - val_mean_squared_error: 2585.0989\n",
      "Epoch 15/100\n",
      "430/430 [==============================] - 0s 115us/step - loss: 2483.1253 - mean_squared_error: 2483.1253 - val_loss: 2080.1985 - val_mean_squared_error: 2080.1985\n",
      "Epoch 16/100\n",
      "430/430 [==============================] - 0s 128us/step - loss: 2089.3570 - mean_squared_error: 2089.3570 - val_loss: 1682.4128 - val_mean_squared_error: 1682.4128\n",
      "Epoch 17/100\n",
      "430/430 [==============================] - 0s 159us/step - loss: 1694.5920 - mean_squared_error: 1694.5920 - val_loss: 1382.4856 - val_mean_squared_error: 1382.4856\n",
      "Epoch 18/100\n",
      "430/430 [==============================] - 0s 162us/step - loss: 1385.3432 - mean_squared_error: 1385.3432 - val_loss: 1185.9763 - val_mean_squared_error: 1185.9763\n",
      "Epoch 19/100\n",
      "430/430 [==============================] - 0s 129us/step - loss: 1170.6166 - mean_squared_error: 1170.6166 - val_loss: 989.2460 - val_mean_squared_error: 989.2460\n",
      "Epoch 20/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 992.4319 - mean_squared_error: 992.4319 - val_loss: 827.5830 - val_mean_squared_error: 827.5830\n",
      "Epoch 21/100\n",
      "430/430 [==============================] - 0s 170us/step - loss: 858.3580 - mean_squared_error: 858.3580 - val_loss: 713.4553 - val_mean_squared_error: 713.4553\n",
      "Epoch 22/100\n",
      "430/430 [==============================] - 0s 142us/step - loss: 726.3657 - mean_squared_error: 726.3657 - val_loss: 607.4196 - val_mean_squared_error: 607.4196\n",
      "Epoch 23/100\n",
      "430/430 [==============================] - 0s 138us/step - loss: 622.5629 - mean_squared_error: 622.5629 - val_loss: 504.7823 - val_mean_squared_error: 504.7823\n",
      "Epoch 24/100\n",
      "430/430 [==============================] - 0s 135us/step - loss: 515.4985 - mean_squared_error: 515.4985 - val_loss: 432.5343 - val_mean_squared_error: 432.5343\n",
      "Epoch 25/100\n",
      "430/430 [==============================] - 0s 143us/step - loss: 381.5097 - mean_squared_error: 381.5097 - val_loss: 246.9575 - val_mean_squared_error: 246.9575\n",
      "Epoch 26/100\n",
      "430/430 [==============================] - 0s 132us/step - loss: 279.5126 - mean_squared_error: 279.5126 - val_loss: 266.0879 - val_mean_squared_error: 266.0879\n",
      "Epoch 27/100\n",
      "430/430 [==============================] - 0s 153us/step - loss: 267.3818 - mean_squared_error: 267.3818 - val_loss: 254.5150 - val_mean_squared_error: 254.5150\n",
      "Epoch 28/100\n",
      "430/430 [==============================] - 0s 190us/step - loss: 266.8536 - mean_squared_error: 266.8536 - val_loss: 196.8018 - val_mean_squared_error: 196.8018\n",
      "Epoch 29/100\n",
      "430/430 [==============================] - 0s 170us/step - loss: 241.4307 - mean_squared_error: 241.4307 - val_loss: 185.6788 - val_mean_squared_error: 185.6788\n",
      "Epoch 30/100\n",
      "430/430 [==============================] - 0s 161us/step - loss: 226.8615 - mean_squared_error: 226.8615 - val_loss: 177.0318 - val_mean_squared_error: 177.0318\n",
      "Epoch 31/100\n",
      "430/430 [==============================] - 0s 164us/step - loss: 215.5616 - mean_squared_error: 215.5616 - val_loss: 176.3705 - val_mean_squared_error: 176.3705\n",
      "Epoch 32/100\n",
      "430/430 [==============================] - 0s 147us/step - loss: 207.9919 - mean_squared_error: 207.9919 - val_loss: 186.2837 - val_mean_squared_error: 186.2837\n",
      "Epoch 33/100\n",
      "430/430 [==============================] - 0s 138us/step - loss: 201.0299 - mean_squared_error: 201.0299 - val_loss: 183.0870 - val_mean_squared_error: 183.0870\n",
      "Epoch 34/100\n",
      "430/430 [==============================] - 0s 133us/step - loss: 215.8481 - mean_squared_error: 215.8481 - val_loss: 164.7350 - val_mean_squared_error: 164.7350\n",
      "Epoch 35/100\n",
      "430/430 [==============================] - 0s 128us/step - loss: 207.2300 - mean_squared_error: 207.2300 - val_loss: 180.4526 - val_mean_squared_error: 180.4526\n",
      "Epoch 36/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 180.9902 - mean_squared_error: 180.9902 - val_loss: 165.4047 - val_mean_squared_error: 165.4047\n",
      "Epoch 37/100\n",
      "430/430 [==============================] - 0s 118us/step - loss: 192.8052 - mean_squared_error: 192.8052 - val_loss: 173.1456 - val_mean_squared_error: 173.1456\n",
      "Epoch 38/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 183.1106 - mean_squared_error: 183.1106 - val_loss: 142.8981 - val_mean_squared_error: 142.8981\n",
      "Epoch 39/100\n",
      "430/430 [==============================] - 0s 117us/step - loss: 182.3886 - mean_squared_error: 182.3886 - val_loss: 147.3705 - val_mean_squared_error: 147.3705\n",
      "Epoch 40/100\n",
      "430/430 [==============================] - 0s 121us/step - loss: 166.8754 - mean_squared_error: 166.8754 - val_loss: 208.7231 - val_mean_squared_error: 208.7231\n",
      "Epoch 41/100\n",
      "430/430 [==============================] - 0s 119us/step - loss: 173.1464 - mean_squared_error: 173.1464 - val_loss: 182.6703 - val_mean_squared_error: 182.6703\n",
      "Epoch 42/100\n",
      "430/430 [==============================] - 0s 120us/step - loss: 159.9775 - mean_squared_error: 159.9775 - val_loss: 134.8780 - val_mean_squared_error: 134.8780\n",
      "Epoch 43/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 153.8989 - mean_squared_error: 153.8989 - val_loss: 151.2004 - val_mean_squared_error: 151.2004\n",
      "Epoch 44/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 176.6033 - mean_squared_error: 176.6033 - val_loss: 199.6129 - val_mean_squared_error: 199.6129\n",
      "Epoch 45/100\n",
      "430/430 [==============================] - 0s 115us/step - loss: 155.8797 - mean_squared_error: 155.8797 - val_loss: 175.4373 - val_mean_squared_error: 175.4373\n",
      "Epoch 46/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 164.9072 - mean_squared_error: 164.9072 - val_loss: 132.5616 - val_mean_squared_error: 132.5616\n",
      "Epoch 47/100\n",
      "430/430 [==============================] - 0s 130us/step - loss: 147.3044 - mean_squared_error: 147.3044 - val_loss: 133.3001 - val_mean_squared_error: 133.3001\n",
      "Epoch 48/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 155.3841 - mean_squared_error: 155.3841 - val_loss: 130.3417 - val_mean_squared_error: 130.3417\n",
      "Epoch 49/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 148.6242 - mean_squared_error: 148.6242 - val_loss: 156.3153 - val_mean_squared_error: 156.3153\n",
      "Epoch 50/100\n",
      "430/430 [==============================] - 0s 109us/step - loss: 141.9058 - mean_squared_error: 141.9058 - val_loss: 178.6015 - val_mean_squared_error: 178.6015\n",
      "Epoch 51/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 143.4867 - mean_squared_error: 143.4867 - val_loss: 140.3787 - val_mean_squared_error: 140.3787\n",
      "Epoch 52/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 185.9324 - mean_squared_error: 185.9324 - val_loss: 146.7639 - val_mean_squared_error: 146.7639\n",
      "Epoch 53/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 138.5799 - mean_squared_error: 138.5799 - val_loss: 145.3707 - val_mean_squared_error: 145.3707\n",
      "Epoch 54/100\n",
      "430/430 [==============================] - 0s 110us/step - loss: 142.3058 - mean_squared_error: 142.3058 - val_loss: 178.3706 - val_mean_squared_error: 178.3706\n",
      "Epoch 55/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 158.0158 - mean_squared_error: 158.0158 - val_loss: 168.7653 - val_mean_squared_error: 168.7653\n",
      "Epoch 56/100\n",
      "430/430 [==============================] - 0s 117us/step - loss: 129.3127 - mean_squared_error: 129.3127 - val_loss: 127.5915 - val_mean_squared_error: 127.5915\n",
      "Epoch 57/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 124.6705 - mean_squared_error: 124.6705 - val_loss: 150.5586 - val_mean_squared_error: 150.5586\n",
      "Epoch 58/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 128.5702 - mean_squared_error: 128.5702 - val_loss: 126.1604 - val_mean_squared_error: 126.1604\n",
      "Epoch 59/100\n",
      "430/430 [==============================] - 0s 114us/step - loss: 138.7744 - mean_squared_error: 138.7744 - val_loss: 146.2502 - val_mean_squared_error: 146.2502\n",
      "Epoch 60/100\n",
      "430/430 [==============================] - 0s 120us/step - loss: 165.3198 - mean_squared_error: 165.3198 - val_loss: 151.7700 - val_mean_squared_error: 151.7700\n",
      "Epoch 61/100\n",
      "430/430 [==============================] - 0s 126us/step - loss: 122.3306 - mean_squared_error: 122.3306 - val_loss: 124.8244 - val_mean_squared_error: 124.8244\n",
      "Epoch 62/100\n",
      "430/430 [==============================] - 0s 132us/step - loss: 115.6348 - mean_squared_error: 115.6348 - val_loss: 119.3678 - val_mean_squared_error: 119.3678\n",
      "Epoch 63/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 124.9450 - mean_squared_error: 124.9450 - val_loss: 212.2066 - val_mean_squared_error: 212.2066\n",
      "Epoch 64/100\n",
      "430/430 [==============================] - 0s 130us/step - loss: 126.6992 - mean_squared_error: 126.6992 - val_loss: 116.5709 - val_mean_squared_error: 116.5709\n",
      "Epoch 65/100\n",
      "430/430 [==============================] - 0s 117us/step - loss: 124.8151 - mean_squared_error: 124.8151 - val_loss: 262.6999 - val_mean_squared_error: 262.6999\n",
      "Epoch 66/100\n",
      "430/430 [==============================] - 0s 120us/step - loss: 129.1355 - mean_squared_error: 129.1355 - val_loss: 121.8891 - val_mean_squared_error: 121.8891\n",
      "Epoch 67/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 119.9010 - mean_squared_error: 119.9010 - val_loss: 217.9656 - val_mean_squared_error: 217.9656\n",
      "Epoch 68/100\n",
      "430/430 [==============================] - 0s 119us/step - loss: 127.4412 - mean_squared_error: 127.4412 - val_loss: 185.8868 - val_mean_squared_error: 185.8868\n",
      "Epoch 69/100\n",
      "430/430 [==============================] - 0s 121us/step - loss: 122.0953 - mean_squared_error: 122.0953 - val_loss: 114.0877 - val_mean_squared_error: 114.0877\n",
      "Epoch 70/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 114.5546 - mean_squared_error: 114.5546 - val_loss: 131.5214 - val_mean_squared_error: 131.5214\n",
      "Epoch 71/100\n",
      "430/430 [==============================] - 0s 128us/step - loss: 121.0146 - mean_squared_error: 121.0146 - val_loss: 173.3017 - val_mean_squared_error: 173.3017\n",
      "Epoch 72/100\n",
      "430/430 [==============================] - 0s 122us/step - loss: 108.6763 - mean_squared_error: 108.6763 - val_loss: 124.3882 - val_mean_squared_error: 124.3882\n",
      "Epoch 73/100\n",
      "430/430 [==============================] - 0s 128us/step - loss: 123.3126 - mean_squared_error: 123.3126 - val_loss: 110.1647 - val_mean_squared_error: 110.1647\n",
      "Epoch 74/100\n",
      "430/430 [==============================] - 0s 129us/step - loss: 103.1228 - mean_squared_error: 103.1228 - val_loss: 106.5161 - val_mean_squared_error: 106.5161\n",
      "Epoch 75/100\n",
      "430/430 [==============================] - 0s 144us/step - loss: 101.1394 - mean_squared_error: 101.1394 - val_loss: 113.7074 - val_mean_squared_error: 113.7074\n",
      "Epoch 76/100\n",
      "430/430 [==============================] - 0s 131us/step - loss: 99.2763 - mean_squared_error: 99.2763 - val_loss: 175.9484 - val_mean_squared_error: 175.9484\n",
      "Epoch 77/100\n",
      "430/430 [==============================] - 0s 122us/step - loss: 115.8749 - mean_squared_error: 115.8749 - val_loss: 170.6920 - val_mean_squared_error: 170.6920\n",
      "Epoch 78/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 122.2907 - mean_squared_error: 122.2907 - val_loss: 100.9226 - val_mean_squared_error: 100.9226\n",
      "Epoch 79/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 110.5941 - mean_squared_error: 110.5941 - val_loss: 276.4231 - val_mean_squared_error: 276.4231\n",
      "Epoch 80/100\n",
      "430/430 [==============================] - 0s 117us/step - loss: 102.3655 - mean_squared_error: 102.3655 - val_loss: 96.6321 - val_mean_squared_error: 96.6321\n",
      "Epoch 81/100\n",
      "430/430 [==============================] - 0s 121us/step - loss: 96.5463 - mean_squared_error: 96.5463 - val_loss: 211.6073 - val_mean_squared_error: 211.6073\n",
      "Epoch 82/100\n",
      "430/430 [==============================] - 0s 121us/step - loss: 168.6194 - mean_squared_error: 168.6194 - val_loss: 175.8375 - val_mean_squared_error: 175.8375\n",
      "Epoch 83/100\n",
      "430/430 [==============================] - 0s 124us/step - loss: 107.9673 - mean_squared_error: 107.9673 - val_loss: 147.7794 - val_mean_squared_error: 147.7794\n",
      "Epoch 84/100\n",
      "430/430 [==============================] - 0s 122us/step - loss: 116.4176 - mean_squared_error: 116.4176 - val_loss: 97.4579 - val_mean_squared_error: 97.4579\n",
      "Epoch 85/100\n",
      "430/430 [==============================] - 0s 118us/step - loss: 99.8253 - mean_squared_error: 99.8253 - val_loss: 136.3150 - val_mean_squared_error: 136.3150\n",
      "Epoch 86/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 109.4271 - mean_squared_error: 109.4271 - val_loss: 348.1569 - val_mean_squared_error: 348.1569\n",
      "Epoch 87/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 139.1718 - mean_squared_error: 139.1718 - val_loss: 103.7662 - val_mean_squared_error: 103.7662\n",
      "Epoch 88/100\n",
      "430/430 [==============================] - 0s 120us/step - loss: 108.2306 - mean_squared_error: 108.2306 - val_loss: 127.3149 - val_mean_squared_error: 127.3149\n",
      "Epoch 89/100\n",
      "430/430 [==============================] - 0s 123us/step - loss: 98.0139 - mean_squared_error: 98.0139 - val_loss: 109.5831 - val_mean_squared_error: 109.5831\n",
      "Epoch 90/100\n",
      "430/430 [==============================] - 0s 126us/step - loss: 95.3412 - mean_squared_error: 95.3412 - val_loss: 298.5076 - val_mean_squared_error: 298.5076\n",
      "Epoch 91/100\n",
      "430/430 [==============================] - 0s 125us/step - loss: 202.0772 - mean_squared_error: 202.0772 - val_loss: 117.6590 - val_mean_squared_error: 117.6590\n",
      "Epoch 92/100\n",
      "430/430 [==============================] - 0s 125us/step - loss: 141.1341 - mean_squared_error: 141.1341 - val_loss: 97.3494 - val_mean_squared_error: 97.3494\n",
      "Epoch 93/100\n",
      "430/430 [==============================] - 0s 122us/step - loss: 121.6996 - mean_squared_error: 121.6996 - val_loss: 219.0862 - val_mean_squared_error: 219.0862\n",
      "Epoch 94/100\n",
      "430/430 [==============================] - 0s 126us/step - loss: 165.5470 - mean_squared_error: 165.5470 - val_loss: 87.5796 - val_mean_squared_error: 87.5796\n",
      "Epoch 95/100\n",
      "430/430 [==============================] - 0s 121us/step - loss: 91.1969 - mean_squared_error: 91.1969 - val_loss: 95.9890 - val_mean_squared_error: 95.9890\n",
      "Epoch 96/100\n",
      "430/430 [==============================] - 0s 118us/step - loss: 96.8910 - mean_squared_error: 96.8910 - val_loss: 142.7588 - val_mean_squared_error: 142.7588\n",
      "Epoch 97/100\n",
      "430/430 [==============================] - 0s 112us/step - loss: 99.0496 - mean_squared_error: 99.0496 - val_loss: 125.3829 - val_mean_squared_error: 125.3829\n",
      "Epoch 98/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 106.3099 - mean_squared_error: 106.3099 - val_loss: 85.8267 - val_mean_squared_error: 85.8267\n",
      "Epoch 99/100\n",
      "430/430 [==============================] - 0s 111us/step - loss: 129.5459 - mean_squared_error: 129.5459 - val_loss: 103.5763 - val_mean_squared_error: 103.5763\n",
      "Epoch 100/100\n",
      "430/430 [==============================] - 0s 116us/step - loss: 92.3091 - mean_squared_error: 92.3091 - val_loss: 227.2018 - val_mean_squared_error: 227.2018\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "training_model = model.fit(training_set[FEATURES].values, \n",
    "          training_set[LABEL].values, \n",
    "          epochs=epochs_value,\n",
    "          batch_size=batch_size_value,\n",
    "          validation_data=(test_set[FEATURES].values, test_set[LABEL].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzoHezKzkHOjNzErOgd7MrOT+P9V/Q6F2P/UxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot MSE, compare with initial plot\n",
    "plt.plot(training_model.history['mean_squared_error'][-50:], 'r+', label='training mean_squared_error')\n",
    "plt.plot(training_model.history['val_mean_squared_error'][-50:], 'y.', label='evaluation mean_squared_error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Mean Squared Error over Epochs')\n",
    "plt.show()\n",
    "\n",
    "#new model:\n",
    "#training MSE: 185.3023, evaluation MSE: 118.8821\n",
    "\n",
    "#original model:\n",
    "#training MSE: 81.7415, evaluation MSE: 94.5644\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,301\n",
      "Trainable params: 1,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "Total parameters = 1,301\n"
     ]
    }
   ],
   "source": [
    "#calc number of new parameters\n",
    "print(model.summary(),'\\n')\n",
    "print('Total parameters = 1,301')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is impact on MSE when using larger network topology? \n",
      "\n",
      "Adding a new layer with 100 nodes did not improve the MSE, instead it increased the MSE.\n",
      "Predictions with a larger network topology were worse on a small data set with only 506 records.\n"
     ]
    }
   ],
   "source": [
    "print('What is impact on MSE when using larger network topology?','\\n')\n",
    "\n",
    "print('Adding a new layer with 100 nodes did not improve the MSE, instead it increased the MSE.')\n",
    "print('Predictions with a larger network topology were worse on a small data set with only 506 records.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: change the value of epochs_value = 100 to epochs_value = 300. what is the learning impact why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update variables\n",
    "learning_rate = 0.01\n",
    "epochs_value = 300\n",
    "batch_size_value = 8\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10,  input_shape=(len(FEATURES),), activation=\"sigmoid\", \n",
    "                                kernel_initializer = tf.random_normal_initializer))\n",
    "model.add(tf.keras.layers.Dense(1,kernel_initializer = tf.random_normal_initializer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.4085709  -0.7519859   0.9253528  -0.08228048  0.6072347  -2.2779963\n",
      "  -1.2393609  -1.4339924   0.46896303  1.6053153 ]\n",
      " [ 0.01852518  1.0100051   0.04783068 -1.9334697  -1.0582252   0.02903952\n",
      "  -0.90989095  0.20021836 -0.41708174 -0.3135062 ]\n",
      " [-0.49662405  0.26587686  0.28850502  0.5575976   0.95340115 -0.3496526\n",
      "  -1.5713049  -1.4910243  -0.59385246  1.9667561 ]\n",
      " [ 1.6364404   1.6482077   0.4114532  -0.3053939  -0.2995816   0.5685124\n",
      "   0.8435663  -0.6476623   1.8215812   0.8613719 ]\n",
      " [ 0.52187824  0.02675389 -0.33632913  0.07081047  1.5873246   0.6988723\n",
      "  -0.5798571  -0.04047091  0.52257365 -0.73919004]\n",
      " [ 0.7119937   0.81507427  0.42281744  0.22445044 -4.161652    1.5839391\n",
      "   0.41782174  0.42605984  0.37755898 -0.2841262 ]\n",
      " [-0.7691108  -0.34225708 -1.4835662  -0.30986515 -1.2736353   0.9807094\n",
      "   1.4318776  -1.7509807  -0.6285634   1.5130093 ]\n",
      " [ 0.00609522  0.01189251  0.4374509  -0.07557318  0.18605141 -0.20990579\n",
      "  -0.03914224  0.09963965  0.00875721 -0.1346639 ]\n",
      " [ 0.5309982  -1.2164246  -1.2780067   0.96844226 -0.9724833   1.15253\n",
      "   0.86460716 -0.91329306  0.22920628  2.041402  ]] \n",
      "\n",
      "(9, 10)\n"
     ]
    }
   ],
   "source": [
    "#get weights\n",
    "layer_input = model.layers[0]\n",
    "print(layer_input.get_weights()[0],'\\n')\n",
    "print(layer_input.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 430 samples, validate on 76 samples\n",
      "Epoch 1/300\n",
      "430/430 [==============================] - 0s 630us/step - loss: 590.0677 - mean_squared_error: 590.0677 - val_loss: 647.8846 - val_mean_squared_error: 647.8846\n",
      "Epoch 2/300\n",
      "430/430 [==============================] - 0s 108us/step - loss: 579.3438 - mean_squared_error: 579.3438 - val_loss: 634.6720 - val_mean_squared_error: 634.6720\n",
      "Epoch 3/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 566.9240 - mean_squared_error: 566.9240 - val_loss: 622.6828 - val_mean_squared_error: 622.6828\n",
      "Epoch 4/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 556.6859 - mean_squared_error: 556.6859 - val_loss: 612.4887 - val_mean_squared_error: 612.4887\n",
      "Epoch 5/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 543.7978 - mean_squared_error: 543.7978 - val_loss: 599.9417 - val_mean_squared_error: 599.9417\n",
      "Epoch 6/300\n",
      "430/430 [==============================] - 0s 145us/step - loss: 532.4317 - mean_squared_error: 532.4317 - val_loss: 590.5536 - val_mean_squared_error: 590.5536\n",
      "Epoch 7/300\n",
      "430/430 [==============================] - 0s 125us/step - loss: 523.1917 - mean_squared_error: 523.1917 - val_loss: 579.2171 - val_mean_squared_error: 579.2171\n",
      "Epoch 8/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 513.9795 - mean_squared_error: 513.9795 - val_loss: 568.9713 - val_mean_squared_error: 568.9713\n",
      "Epoch 9/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 504.6243 - mean_squared_error: 504.6243 - val_loss: 559.7305 - val_mean_squared_error: 559.7305\n",
      "Epoch 10/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 496.0809 - mean_squared_error: 496.0809 - val_loss: 550.9160 - val_mean_squared_error: 550.9160\n",
      "Epoch 11/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 487.9438 - mean_squared_error: 487.9438 - val_loss: 542.3359 - val_mean_squared_error: 542.3359\n",
      "Epoch 12/300\n",
      "430/430 [==============================] - 0s 141us/step - loss: 479.9349 - mean_squared_error: 479.9349 - val_loss: 533.9357 - val_mean_squared_error: 533.9357\n",
      "Epoch 13/300\n",
      "430/430 [==============================] - 0s 120us/step - loss: 472.0791 - mean_squared_error: 472.0791 - val_loss: 525.5724 - val_mean_squared_error: 525.5724\n",
      "Epoch 14/300\n",
      "430/430 [==============================] - 0s 123us/step - loss: 464.3143 - mean_squared_error: 464.3143 - val_loss: 517.4412 - val_mean_squared_error: 517.4412\n",
      "Epoch 15/300\n",
      "430/430 [==============================] - 0s 107us/step - loss: 456.7133 - mean_squared_error: 456.7133 - val_loss: 509.2461 - val_mean_squared_error: 509.2461\n",
      "Epoch 16/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 449.1872 - mean_squared_error: 449.1872 - val_loss: 501.3396 - val_mean_squared_error: 501.3396\n",
      "Epoch 17/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 441.8218 - mean_squared_error: 441.8218 - val_loss: 493.4105 - val_mean_squared_error: 493.4105\n",
      "Epoch 18/300\n",
      "430/430 [==============================] - 0s 131us/step - loss: 434.5324 - mean_squared_error: 434.5324 - val_loss: 485.7169 - val_mean_squared_error: 485.7169\n",
      "Epoch 19/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 427.3535 - mean_squared_error: 427.3535 - val_loss: 478.0996 - val_mean_squared_error: 478.0996\n",
      "Epoch 20/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 420.2761 - mean_squared_error: 420.2761 - val_loss: 470.3636 - val_mean_squared_error: 470.3636\n",
      "Epoch 21/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 412.5726 - mean_squared_error: 412.5726 - val_loss: 461.6652 - val_mean_squared_error: 461.6652\n",
      "Epoch 22/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 405.3099 - mean_squared_error: 405.3099 - val_loss: 454.1311 - val_mean_squared_error: 454.1311\n",
      "Epoch 23/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 396.3381 - mean_squared_error: 396.3381 - val_loss: 444.6271 - val_mean_squared_error: 444.6271\n",
      "Epoch 24/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 388.6086 - mean_squared_error: 388.6086 - val_loss: 437.5477 - val_mean_squared_error: 437.5477\n",
      "Epoch 25/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 381.9615 - mean_squared_error: 381.9615 - val_loss: 430.5317 - val_mean_squared_error: 430.5317\n",
      "Epoch 26/300\n",
      "430/430 [==============================] - 0s 103us/step - loss: 375.1476 - mean_squared_error: 375.1476 - val_loss: 423.1167 - val_mean_squared_error: 423.1167\n",
      "Epoch 27/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 367.6912 - mean_squared_error: 367.6912 - val_loss: 415.2449 - val_mean_squared_error: 415.2449\n",
      "Epoch 28/300\n",
      "430/430 [==============================] - 0s 105us/step - loss: 360.5151 - mean_squared_error: 360.5151 - val_loss: 408.5007 - val_mean_squared_error: 408.5007\n",
      "Epoch 29/300\n",
      "430/430 [==============================] - 0s 119us/step - loss: 354.2034 - mean_squared_error: 354.2034 - val_loss: 401.8014 - val_mean_squared_error: 401.8014\n",
      "Epoch 30/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 348.0020 - mean_squared_error: 348.0020 - val_loss: 395.0934 - val_mean_squared_error: 395.0934\n",
      "Epoch 31/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 341.5880 - mean_squared_error: 341.5880 - val_loss: 388.7074 - val_mean_squared_error: 388.7074\n",
      "Epoch 32/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 335.5593 - mean_squared_error: 335.5593 - val_loss: 382.2289 - val_mean_squared_error: 382.2289\n",
      "Epoch 33/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 329.5133 - mean_squared_error: 329.5133 - val_loss: 375.4845 - val_mean_squared_error: 375.4845\n",
      "Epoch 34/300\n",
      "430/430 [==============================] - 0s 118us/step - loss: 323.5844 - mean_squared_error: 323.5844 - val_loss: 368.3389 - val_mean_squared_error: 368.3389\n",
      "Epoch 35/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 317.3764 - mean_squared_error: 317.3764 - val_loss: 361.7969 - val_mean_squared_error: 361.7969\n",
      "Epoch 36/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 311.2858 - mean_squared_error: 311.2858 - val_loss: 355.7276 - val_mean_squared_error: 355.7276\n",
      "Epoch 37/300\n",
      "430/430 [==============================] - 0s 151us/step - loss: 305.6624 - mean_squared_error: 305.6624 - val_loss: 349.7968 - val_mean_squared_error: 349.7968\n",
      "Epoch 38/300\n",
      "430/430 [==============================] - 0s 126us/step - loss: 299.7626 - mean_squared_error: 299.7626 - val_loss: 343.9927 - val_mean_squared_error: 343.9927\n",
      "Epoch 39/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 294.2314 - mean_squared_error: 294.2314 - val_loss: 338.2186 - val_mean_squared_error: 338.2186\n",
      "Epoch 40/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 288.8945 - mean_squared_error: 288.8945 - val_loss: 332.5104 - val_mean_squared_error: 332.5104\n",
      "Epoch 41/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 283.7066 - mean_squared_error: 283.7066 - val_loss: 326.9005 - val_mean_squared_error: 326.9005\n",
      "Epoch 42/300\n",
      "430/430 [==============================] - 0s 101us/step - loss: 278.5950 - mean_squared_error: 278.5950 - val_loss: 321.4888 - val_mean_squared_error: 321.4888\n",
      "Epoch 43/300\n",
      "430/430 [==============================] - 0s 123us/step - loss: 273.5922 - mean_squared_error: 273.5922 - val_loss: 316.1295 - val_mean_squared_error: 316.1295\n",
      "Epoch 44/300\n",
      "430/430 [==============================] - 0s 173us/step - loss: 268.6718 - mean_squared_error: 268.6718 - val_loss: 310.8163 - val_mean_squared_error: 310.8163\n",
      "Epoch 45/300\n",
      "430/430 [==============================] - 0s 205us/step - loss: 263.8502 - mean_squared_error: 263.8502 - val_loss: 305.5034 - val_mean_squared_error: 305.5034\n",
      "Epoch 46/300\n",
      "430/430 [==============================] - 0s 163us/step - loss: 259.0698 - mean_squared_error: 259.0698 - val_loss: 300.4569 - val_mean_squared_error: 300.4569\n",
      "Epoch 47/300\n",
      "430/430 [==============================] - 0s 123us/step - loss: 254.4322 - mean_squared_error: 254.4322 - val_loss: 295.3855 - val_mean_squared_error: 295.3855\n",
      "Epoch 48/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 249.8532 - mean_squared_error: 249.8532 - val_loss: 290.3944 - val_mean_squared_error: 290.3944\n",
      "Epoch 49/300\n",
      "430/430 [==============================] - 0s 166us/step - loss: 245.3522 - mean_squared_error: 245.3522 - val_loss: 285.5569 - val_mean_squared_error: 285.5569\n",
      "Epoch 50/300\n",
      "430/430 [==============================] - 0s 157us/step - loss: 240.9349 - mean_squared_error: 240.9349 - val_loss: 280.8575 - val_mean_squared_error: 280.8575\n",
      "Epoch 51/300\n",
      "430/430 [==============================] - 0s 124us/step - loss: 236.6207 - mean_squared_error: 236.6207 - val_loss: 276.0796 - val_mean_squared_error: 276.0796\n",
      "Epoch 52/300\n",
      "430/430 [==============================] - 0s 125us/step - loss: 232.3727 - mean_squared_error: 232.3727 - val_loss: 271.3989 - val_mean_squared_error: 271.3989\n",
      "Epoch 53/300\n",
      "430/430 [==============================] - 0s 139us/step - loss: 228.1946 - mean_squared_error: 228.1946 - val_loss: 266.8626 - val_mean_squared_error: 266.8626\n",
      "Epoch 54/300\n",
      "430/430 [==============================] - 0s 145us/step - loss: 224.0870 - mean_squared_error: 224.0870 - val_loss: 262.4768 - val_mean_squared_error: 262.4768\n",
      "Epoch 55/300\n",
      "430/430 [==============================] - 0s 148us/step - loss: 220.0983 - mean_squared_error: 220.0983 - val_loss: 258.0197 - val_mean_squared_error: 258.0197\n",
      "Epoch 56/300\n",
      "430/430 [==============================] - 0s 160us/step - loss: 216.1334 - mean_squared_error: 216.1334 - val_loss: 253.7671 - val_mean_squared_error: 253.7671\n",
      "Epoch 57/300\n",
      "430/430 [==============================] - 0s 167us/step - loss: 212.2887 - mean_squared_error: 212.2887 - val_loss: 249.4962 - val_mean_squared_error: 249.4962\n",
      "Epoch 58/300\n",
      "430/430 [==============================] - 0s 169us/step - loss: 208.0489 - mean_squared_error: 208.0489 - val_loss: 245.3320 - val_mean_squared_error: 245.3320\n",
      "Epoch 59/300\n",
      "430/430 [==============================] - 0s 168us/step - loss: 203.9703 - mean_squared_error: 203.9703 - val_loss: 241.2963 - val_mean_squared_error: 241.2963\n",
      "Epoch 60/300\n",
      "430/430 [==============================] - 0s 138us/step - loss: 200.3204 - mean_squared_error: 200.3204 - val_loss: 237.3259 - val_mean_squared_error: 237.3259\n",
      "Epoch 61/300\n",
      "430/430 [==============================] - 0s 104us/step - loss: 196.7080 - mean_squared_error: 196.7080 - val_loss: 233.4368 - val_mean_squared_error: 233.4368\n",
      "Epoch 62/300\n",
      "430/430 [==============================] - 0s 103us/step - loss: 192.9645 - mean_squared_error: 192.9645 - val_loss: 229.5964 - val_mean_squared_error: 229.5964\n",
      "Epoch 63/300\n",
      "430/430 [==============================] - 0s 105us/step - loss: 189.5467 - mean_squared_error: 189.5467 - val_loss: 225.7841 - val_mean_squared_error: 225.7841\n",
      "Epoch 64/300\n",
      "430/430 [==============================] - 0s 108us/step - loss: 186.2036 - mean_squared_error: 186.2036 - val_loss: 222.0643 - val_mean_squared_error: 222.0643\n",
      "Epoch 65/300\n",
      "430/430 [==============================] - 0s 107us/step - loss: 182.9262 - mean_squared_error: 182.9262 - val_loss: 218.4390 - val_mean_squared_error: 218.4390\n",
      "Epoch 66/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 179.7122 - mean_squared_error: 179.7122 - val_loss: 214.9435 - val_mean_squared_error: 214.9435\n",
      "Epoch 67/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 176.5894 - mean_squared_error: 176.5894 - val_loss: 211.3828 - val_mean_squared_error: 211.3828\n",
      "Epoch 68/300\n",
      "430/430 [==============================] - 0s 127us/step - loss: 173.5107 - mean_squared_error: 173.5107 - val_loss: 207.9876 - val_mean_squared_error: 207.9876\n",
      "Epoch 69/300\n",
      "430/430 [==============================] - 0s 149us/step - loss: 170.5120 - mean_squared_error: 170.5120 - val_loss: 204.6468 - val_mean_squared_error: 204.6468\n",
      "Epoch 70/300\n",
      "430/430 [==============================] - 0s 119us/step - loss: 167.5823 - mean_squared_error: 167.5823 - val_loss: 201.4168 - val_mean_squared_error: 201.4168\n",
      "Epoch 71/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 164.7257 - mean_squared_error: 164.7257 - val_loss: 198.1033 - val_mean_squared_error: 198.1033\n",
      "Epoch 72/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 161.9032 - mean_squared_error: 161.9032 - val_loss: 195.0083 - val_mean_squared_error: 195.0083\n",
      "Epoch 73/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 159.1869 - mean_squared_error: 159.1869 - val_loss: 191.8740 - val_mean_squared_error: 191.8740\n",
      "Epoch 74/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 156.4875 - mean_squared_error: 156.4875 - val_loss: 188.9902 - val_mean_squared_error: 188.9902\n",
      "Epoch 75/300\n",
      "430/430 [==============================] - 0s 101us/step - loss: 153.8903 - mean_squared_error: 153.8903 - val_loss: 185.9629 - val_mean_squared_error: 185.9629\n",
      "Epoch 76/300\n",
      "430/430 [==============================] - 0s 104us/step - loss: 151.3346 - mean_squared_error: 151.3346 - val_loss: 183.0262 - val_mean_squared_error: 183.0262\n",
      "Epoch 77/300\n",
      "430/430 [==============================] - 0s 101us/step - loss: 148.8270 - mean_squared_error: 148.8270 - val_loss: 180.2912 - val_mean_squared_error: 180.2912\n",
      "Epoch 78/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 146.4141 - mean_squared_error: 146.4141 - val_loss: 177.4710 - val_mean_squared_error: 177.4710\n",
      "Epoch 79/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 144.0333 - mean_squared_error: 144.0333 - val_loss: 174.7974 - val_mean_squared_error: 174.7974\n",
      "Epoch 80/300\n",
      "430/430 [==============================] - 0s 105us/step - loss: 141.7399 - mean_squared_error: 141.7399 - val_loss: 172.1161 - val_mean_squared_error: 172.1161\n",
      "Epoch 81/300\n",
      "430/430 [==============================] - 0s 102us/step - loss: 139.4822 - mean_squared_error: 139.4822 - val_loss: 169.5695 - val_mean_squared_error: 169.5695\n",
      "Epoch 82/300\n",
      "430/430 [==============================] - 0s 104us/step - loss: 137.2962 - mean_squared_error: 137.2962 - val_loss: 167.0475 - val_mean_squared_error: 167.0475\n",
      "Epoch 83/300\n",
      "430/430 [==============================] - 0s 102us/step - loss: 135.1653 - mean_squared_error: 135.1653 - val_loss: 164.5972 - val_mean_squared_error: 164.5972\n",
      "Epoch 84/300\n",
      "430/430 [==============================] - 0s 101us/step - loss: 133.0882 - mean_squared_error: 133.0882 - val_loss: 162.2395 - val_mean_squared_error: 162.2395\n",
      "Epoch 85/300\n",
      "430/430 [==============================] - 0s 106us/step - loss: 131.0679 - mean_squared_error: 131.0679 - val_loss: 159.8957 - val_mean_squared_error: 159.8957\n",
      "Epoch 86/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 129.1167 - mean_squared_error: 129.1167 - val_loss: 157.5515 - val_mean_squared_error: 157.5515\n",
      "Epoch 87/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 127.1849 - mean_squared_error: 127.1849 - val_loss: 155.4130 - val_mean_squared_error: 155.4130\n",
      "Epoch 88/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 125.3509 - mean_squared_error: 125.3509 - val_loss: 153.1755 - val_mean_squared_error: 153.1755\n",
      "Epoch 89/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 123.5327 - mean_squared_error: 123.5327 - val_loss: 151.0933 - val_mean_squared_error: 151.0933\n",
      "Epoch 90/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 121.7930 - mean_squared_error: 121.7930 - val_loss: 149.0461 - val_mean_squared_error: 149.0461\n",
      "Epoch 91/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 120.0958 - mean_squared_error: 120.0958 - val_loss: 147.0485 - val_mean_squared_error: 147.0485\n",
      "Epoch 92/300\n",
      "430/430 [==============================] - 0s 107us/step - loss: 118.4379 - mean_squared_error: 118.4379 - val_loss: 145.1322 - val_mean_squared_error: 145.1322\n",
      "Epoch 93/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 116.8406 - mean_squared_error: 116.8406 - val_loss: 143.2323 - val_mean_squared_error: 143.2323\n",
      "Epoch 94/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 115.2877 - mean_squared_error: 115.2877 - val_loss: 141.3614 - val_mean_squared_error: 141.3614\n",
      "Epoch 95/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 113.7890 - mean_squared_error: 113.7890 - val_loss: 139.5563 - val_mean_squared_error: 139.5563\n",
      "Epoch 96/300\n",
      "430/430 [==============================] - 0s 101us/step - loss: 112.3445 - mean_squared_error: 112.3445 - val_loss: 137.7775 - val_mean_squared_error: 137.7775\n",
      "Epoch 97/300\n",
      "430/430 [==============================] - 0s 99us/step - loss: 110.9398 - mean_squared_error: 110.9398 - val_loss: 136.1158 - val_mean_squared_error: 136.1158\n",
      "Epoch 98/300\n",
      "430/430 [==============================] - 0s 103us/step - loss: 109.6042 - mean_squared_error: 109.6042 - val_loss: 134.4461 - val_mean_squared_error: 134.4461\n",
      "Epoch 99/300\n",
      "430/430 [==============================] - 0s 104us/step - loss: 108.2830 - mean_squared_error: 108.2830 - val_loss: 132.9119 - val_mean_squared_error: 132.9119\n",
      "Epoch 100/300\n",
      "430/430 [==============================] - 0s 101us/step - loss: 107.0355 - mean_squared_error: 107.0355 - val_loss: 131.3647 - val_mean_squared_error: 131.3647\n",
      "Epoch 101/300\n",
      "430/430 [==============================] - 0s 105us/step - loss: 105.8236 - mean_squared_error: 105.8236 - val_loss: 129.8524 - val_mean_squared_error: 129.8524\n",
      "Epoch 102/300\n",
      "430/430 [==============================] - 0s 99us/step - loss: 104.6359 - mean_squared_error: 104.6359 - val_loss: 128.5019 - val_mean_squared_error: 128.5019\n",
      "Epoch 103/300\n",
      "430/430 [==============================] - 0s 102us/step - loss: 103.5194 - mean_squared_error: 103.5194 - val_loss: 127.0185 - val_mean_squared_error: 127.0185\n",
      "Epoch 104/300\n",
      "430/430 [==============================] - 0s 104us/step - loss: 102.4244 - mean_squared_error: 102.4244 - val_loss: 125.6559 - val_mean_squared_error: 125.6559\n",
      "Epoch 105/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 101.3762 - mean_squared_error: 101.3762 - val_loss: 124.4302 - val_mean_squared_error: 124.4302\n",
      "Epoch 106/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 100.3909 - mean_squared_error: 100.3909 - val_loss: 123.0868 - val_mean_squared_error: 123.0868\n",
      "Epoch 107/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 99.4078 - mean_squared_error: 99.4078 - val_loss: 121.9378 - val_mean_squared_error: 121.9378\n",
      "Epoch 108/300\n",
      "430/430 [==============================] - 0s 126us/step - loss: 98.4946 - mean_squared_error: 98.4946 - val_loss: 120.7055 - val_mean_squared_error: 120.7055\n",
      "Epoch 109/300\n",
      "430/430 [==============================] - 0s 143us/step - loss: 97.5920 - mean_squared_error: 97.5920 - val_loss: 119.6424 - val_mean_squared_error: 119.6424\n",
      "Epoch 110/300\n",
      "430/430 [==============================] - 0s 131us/step - loss: 96.7627 - mean_squared_error: 96.7627 - val_loss: 118.4222 - val_mean_squared_error: 118.4222\n",
      "Epoch 111/300\n",
      "430/430 [==============================] - 0s 124us/step - loss: 95.9280 - mean_squared_error: 95.9280 - val_loss: 117.4027 - val_mean_squared_error: 117.4027\n",
      "Epoch 112/300\n",
      "430/430 [==============================] - 0s 121us/step - loss: 95.1543 - mean_squared_error: 95.1543 - val_loss: 116.4000 - val_mean_squared_error: 116.4000\n",
      "Epoch 113/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 94.4158 - mean_squared_error: 94.4158 - val_loss: 115.4312 - val_mean_squared_error: 115.4312\n",
      "Epoch 114/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 93.7002 - mean_squared_error: 93.7002 - val_loss: 114.4903 - val_mean_squared_error: 114.4903\n",
      "Epoch 115/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 93.0171 - mean_squared_error: 93.0171 - val_loss: 113.6167 - val_mean_squared_error: 113.6167\n",
      "Epoch 116/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 92.3761 - mean_squared_error: 92.3761 - val_loss: 112.7402 - val_mean_squared_error: 112.7402\n",
      "Epoch 117/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 91.7622 - mean_squared_error: 91.7622 - val_loss: 111.8578 - val_mean_squared_error: 111.8578\n",
      "Epoch 118/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 91.1664 - mean_squared_error: 91.1664 - val_loss: 111.0832 - val_mean_squared_error: 111.0832\n",
      "Epoch 119/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 90.6128 - mean_squared_error: 90.6128 - val_loss: 110.2916 - val_mean_squared_error: 110.2916\n",
      "Epoch 120/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 90.0814 - mean_squared_error: 90.0814 - val_loss: 109.5717 - val_mean_squared_error: 109.5717\n",
      "Epoch 121/300\n",
      "430/430 [==============================] - 0s 127us/step - loss: 89.5904 - mean_squared_error: 89.5904 - val_loss: 108.8189 - val_mean_squared_error: 108.8189\n",
      "Epoch 122/300\n",
      "430/430 [==============================] - 0s 151us/step - loss: 89.1005 - mean_squared_error: 89.1005 - val_loss: 108.2009 - val_mean_squared_error: 108.2009\n",
      "Epoch 123/300\n",
      "430/430 [==============================] - 0s 165us/step - loss: 88.6734 - mean_squared_error: 88.6734 - val_loss: 107.4628 - val_mean_squared_error: 107.4628\n",
      "Epoch 124/300\n",
      "430/430 [==============================] - 0s 149us/step - loss: 88.2225 - mean_squared_error: 88.2225 - val_loss: 106.9270 - val_mean_squared_error: 106.9270\n",
      "Epoch 125/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 87.8389 - mean_squared_error: 87.8389 - val_loss: 106.2868 - val_mean_squared_error: 106.2868\n",
      "Epoch 126/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 87.4613 - mean_squared_error: 87.4613 - val_loss: 105.6919 - val_mean_squared_error: 105.6919\n",
      "Epoch 127/300\n",
      "430/430 [==============================] - 0s 126us/step - loss: 87.0887 - mean_squared_error: 87.0887 - val_loss: 105.1878 - val_mean_squared_error: 105.1878\n",
      "Epoch 128/300\n",
      "430/430 [==============================] - 0s 174us/step - loss: 86.7591 - mean_squared_error: 86.7591 - val_loss: 104.6692 - val_mean_squared_error: 104.6692\n",
      "Epoch 129/300\n",
      "430/430 [==============================] - 0s 152us/step - loss: 86.4467 - mean_squared_error: 86.4467 - val_loss: 104.1567 - val_mean_squared_error: 104.1567\n",
      "Epoch 130/300\n",
      "430/430 [==============================] - 0s 151us/step - loss: 86.1483 - mean_squared_error: 86.1483 - val_loss: 103.7098 - val_mean_squared_error: 103.7098\n",
      "Epoch 131/300\n",
      "430/430 [==============================] - 0s 173us/step - loss: 85.8704 - mean_squared_error: 85.8704 - val_loss: 103.2470 - val_mean_squared_error: 103.2470\n",
      "Epoch 132/300\n",
      "430/430 [==============================] - 0s 173us/step - loss: 85.6103 - mean_squared_error: 85.6103 - val_loss: 102.8356 - val_mean_squared_error: 102.8356\n",
      "Epoch 133/300\n",
      "430/430 [==============================] - 0s 154us/step - loss: 85.3640 - mean_squared_error: 85.3640 - val_loss: 102.4909 - val_mean_squared_error: 102.4909\n",
      "Epoch 134/300\n",
      "430/430 [==============================] - 0s 157us/step - loss: 85.1479 - mean_squared_error: 85.1479 - val_loss: 102.0741 - val_mean_squared_error: 102.0741\n",
      "Epoch 135/300\n",
      "430/430 [==============================] - 0s 172us/step - loss: 84.9281 - mean_squared_error: 84.9281 - val_loss: 101.6985 - val_mean_squared_error: 101.6985\n",
      "Epoch 136/300\n",
      "430/430 [==============================] - 0s 166us/step - loss: 84.7268 - mean_squared_error: 84.7268 - val_loss: 101.3736 - val_mean_squared_error: 101.3736\n",
      "Epoch 137/300\n",
      "430/430 [==============================] - 0s 181us/step - loss: 84.5407 - mean_squared_error: 84.5407 - val_loss: 101.0499 - val_mean_squared_error: 101.0499\n",
      "Epoch 138/300\n",
      "430/430 [==============================] - 0s 157us/step - loss: 84.3816 - mean_squared_error: 84.3816 - val_loss: 100.6853 - val_mean_squared_error: 100.6853\n",
      "Epoch 139/300\n",
      "430/430 [==============================] - 0s 147us/step - loss: 84.2048 - mean_squared_error: 84.2048 - val_loss: 100.4251 - val_mean_squared_error: 100.4251\n",
      "Epoch 140/300\n",
      "430/430 [==============================] - 0s 128us/step - loss: 84.0621 - mean_squared_error: 84.0621 - val_loss: 100.1731 - val_mean_squared_error: 100.1731\n",
      "Epoch 141/300\n",
      "430/430 [==============================] - 0s 124us/step - loss: 83.9316 - mean_squared_error: 83.9316 - val_loss: 99.8589 - val_mean_squared_error: 99.8589\n",
      "Epoch 142/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 83.7974 - mean_squared_error: 83.7974 - val_loss: 99.6406 - val_mean_squared_error: 99.6406\n",
      "Epoch 143/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 83.6829 - mean_squared_error: 83.6829 - val_loss: 99.4212 - val_mean_squared_error: 99.4212\n",
      "Epoch 144/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 83.5771 - mean_squared_error: 83.5771 - val_loss: 99.1877 - val_mean_squared_error: 99.1877\n",
      "Epoch 145/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 83.4908 - mean_squared_error: 83.4908 - val_loss: 98.9328 - val_mean_squared_error: 98.9328\n",
      "Epoch 146/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 83.3890 - mean_squared_error: 83.3890 - val_loss: 98.7587 - val_mean_squared_error: 98.7587\n",
      "Epoch 147/300\n",
      "430/430 [==============================] - 0s 108us/step - loss: 83.3047 - mean_squared_error: 83.3047 - val_loss: 98.6003 - val_mean_squared_error: 98.6003\n",
      "Epoch 148/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 83.2337 - mean_squared_error: 83.2337 - val_loss: 98.4421 - val_mean_squared_error: 98.4421\n",
      "Epoch 149/300\n",
      "430/430 [==============================] - 0s 122us/step - loss: 83.1618 - mean_squared_error: 83.1618 - val_loss: 98.2531 - val_mean_squared_error: 98.2531\n",
      "Epoch 150/300\n",
      "430/430 [==============================] - 0s 124us/step - loss: 83.1008 - mean_squared_error: 83.1008 - val_loss: 98.0702 - val_mean_squared_error: 98.0702\n",
      "Epoch 151/300\n",
      "430/430 [==============================] - 0s 150us/step - loss: 83.0423 - mean_squared_error: 83.0423 - val_loss: 97.9942 - val_mean_squared_error: 97.9942\n",
      "Epoch 152/300\n",
      "430/430 [==============================] - 0s 151us/step - loss: 82.9843 - mean_squared_error: 82.9843 - val_loss: 97.8222 - val_mean_squared_error: 97.8222\n",
      "Epoch 153/300\n",
      "430/430 [==============================] - 0s 130us/step - loss: 82.9365 - mean_squared_error: 82.9365 - val_loss: 97.6609 - val_mean_squared_error: 97.6609\n",
      "Epoch 154/300\n",
      "430/430 [==============================] - 0s 118us/step - loss: 82.8960 - mean_squared_error: 82.8960 - val_loss: 97.5113 - val_mean_squared_error: 97.5113\n",
      "Epoch 155/300\n",
      "430/430 [==============================] - 0s 118us/step - loss: 82.8645 - mean_squared_error: 82.8645 - val_loss: 97.4254 - val_mean_squared_error: 97.4254\n",
      "Epoch 156/300\n",
      "430/430 [==============================] - 0s 119us/step - loss: 82.8272 - mean_squared_error: 82.8272 - val_loss: 97.3072 - val_mean_squared_error: 97.3072\n",
      "Epoch 157/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 82.7886 - mean_squared_error: 82.7886 - val_loss: 97.2197 - val_mean_squared_error: 97.2197\n",
      "Epoch 158/300\n",
      "430/430 [==============================] - 0s 107us/step - loss: 82.7843 - mean_squared_error: 82.7843 - val_loss: 97.1798 - val_mean_squared_error: 97.1798\n",
      "Epoch 159/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.7365 - mean_squared_error: 82.7365 - val_loss: 97.0645 - val_mean_squared_error: 97.0645\n",
      "Epoch 160/300\n",
      "430/430 [==============================] - 0s 104us/step - loss: 82.7105 - mean_squared_error: 82.7105 - val_loss: 96.9751 - val_mean_squared_error: 96.9751\n",
      "Epoch 161/300\n",
      "430/430 [==============================] - 0s 101us/step - loss: 82.6922 - mean_squared_error: 82.6922 - val_loss: 96.8823 - val_mean_squared_error: 96.8823\n",
      "Epoch 162/300\n",
      "430/430 [==============================] - 0s 105us/step - loss: 82.6743 - mean_squared_error: 82.6743 - val_loss: 96.8186 - val_mean_squared_error: 96.8186\n",
      "Epoch 163/300\n",
      "430/430 [==============================] - 0s 104us/step - loss: 82.6584 - mean_squared_error: 82.6584 - val_loss: 96.7273 - val_mean_squared_error: 96.7273\n",
      "Epoch 164/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 82.6354 - mean_squared_error: 82.6354 - val_loss: 96.6825 - val_mean_squared_error: 96.6825\n",
      "Epoch 165/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.6241 - mean_squared_error: 82.6241 - val_loss: 96.6387 - val_mean_squared_error: 96.6387\n",
      "Epoch 166/300\n",
      "430/430 [==============================] - 0s 123us/step - loss: 82.6191 - mean_squared_error: 82.6191 - val_loss: 96.5542 - val_mean_squared_error: 96.5542\n",
      "Epoch 167/300\n",
      "430/430 [==============================] - 0s 118us/step - loss: 82.6018 - mean_squared_error: 82.6018 - val_loss: 96.4980 - val_mean_squared_error: 96.4980\n",
      "Epoch 168/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 82.5937 - mean_squared_error: 82.5937 - val_loss: 96.4555 - val_mean_squared_error: 96.4555\n",
      "Epoch 169/300\n",
      "430/430 [==============================] - 0s 120us/step - loss: 82.6063 - mean_squared_error: 82.6063 - val_loss: 96.3976 - val_mean_squared_error: 96.3976\n",
      "Epoch 170/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5726 - mean_squared_error: 82.5726 - val_loss: 96.3864 - val_mean_squared_error: 96.3864\n",
      "Epoch 171/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 82.5810 - mean_squared_error: 82.5810 - val_loss: 96.3478 - val_mean_squared_error: 96.3478\n",
      "Epoch 172/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 82.5641 - mean_squared_error: 82.5641 - val_loss: 96.2962 - val_mean_squared_error: 96.2962\n",
      "Epoch 173/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5574 - mean_squared_error: 82.5574 - val_loss: 96.2620 - val_mean_squared_error: 96.2620\n",
      "Epoch 174/300\n",
      "430/430 [==============================] - 0s 130us/step - loss: 82.5512 - mean_squared_error: 82.5512 - val_loss: 96.2257 - val_mean_squared_error: 96.2257\n",
      "Epoch 175/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5474 - mean_squared_error: 82.5474 - val_loss: 96.2185 - val_mean_squared_error: 96.2185\n",
      "Epoch 176/300\n",
      "430/430 [==============================] - 0s 108us/step - loss: 82.5482 - mean_squared_error: 82.5482 - val_loss: 96.1774 - val_mean_squared_error: 96.1774\n",
      "Epoch 177/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 82.5482 - mean_squared_error: 82.5482 - val_loss: 96.1434 - val_mean_squared_error: 96.1434\n",
      "Epoch 178/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 82.5382 - mean_squared_error: 82.5382 - val_loss: 96.1121 - val_mean_squared_error: 96.1121\n",
      "Epoch 179/300\n",
      "430/430 [==============================] - 0s 120us/step - loss: 82.5565 - mean_squared_error: 82.5565 - val_loss: 96.0971 - val_mean_squared_error: 96.0971\n",
      "Epoch 180/300\n",
      "430/430 [==============================] - 0s 180us/step - loss: 82.5353 - mean_squared_error: 82.5353 - val_loss: 96.0720 - val_mean_squared_error: 96.0720\n",
      "Epoch 181/300\n",
      "430/430 [==============================] - 0s 152us/step - loss: 82.5364 - mean_squared_error: 82.5364 - val_loss: 96.0724 - val_mean_squared_error: 96.0724\n",
      "Epoch 182/300\n",
      "430/430 [==============================] - 0s 119us/step - loss: 82.5341 - mean_squared_error: 82.5341 - val_loss: 96.0401 - val_mean_squared_error: 96.0401\n",
      "Epoch 183/300\n",
      "430/430 [==============================] - 0s 123us/step - loss: 82.5254 - mean_squared_error: 82.5254 - val_loss: 96.0336 - val_mean_squared_error: 96.0336\n",
      "Epoch 184/300\n",
      "430/430 [==============================] - 0s 168us/step - loss: 82.5257 - mean_squared_error: 82.5257 - val_loss: 96.0113 - val_mean_squared_error: 96.0113\n",
      "Epoch 185/300\n",
      "430/430 [==============================] - 0s 131us/step - loss: 82.5231 - mean_squared_error: 82.5231 - val_loss: 95.9951 - val_mean_squared_error: 95.9951\n",
      "Epoch 186/300\n",
      "430/430 [==============================] - 0s 119us/step - loss: 82.5293 - mean_squared_error: 82.5293 - val_loss: 95.9592 - val_mean_squared_error: 95.9592\n",
      "Epoch 187/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.5273 - mean_squared_error: 82.5273 - val_loss: 95.9483 - val_mean_squared_error: 95.9483\n",
      "Epoch 188/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 82.5172 - mean_squared_error: 82.5172 - val_loss: 95.9413 - val_mean_squared_error: 95.9413\n",
      "Epoch 189/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 82.5226 - mean_squared_error: 82.5226 - val_loss: 95.9041 - val_mean_squared_error: 95.9041\n",
      "Epoch 190/300\n",
      "430/430 [==============================] - 0s 162us/step - loss: 82.5217 - mean_squared_error: 82.5217 - val_loss: 95.9036 - val_mean_squared_error: 95.9036\n",
      "Epoch 191/300\n",
      "430/430 [==============================] - 0s 154us/step - loss: 82.5205 - mean_squared_error: 82.5205 - val_loss: 95.8859 - val_mean_squared_error: 95.8859\n",
      "Epoch 192/300\n",
      "430/430 [==============================] - 0s 120us/step - loss: 82.5162 - mean_squared_error: 82.5162 - val_loss: 95.8964 - val_mean_squared_error: 95.8964\n",
      "Epoch 193/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5232 - mean_squared_error: 82.5232 - val_loss: 95.8863 - val_mean_squared_error: 95.8863\n",
      "Epoch 194/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5170 - mean_squared_error: 82.5170 - val_loss: 95.8887 - val_mean_squared_error: 95.8887\n",
      "Epoch 195/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 82.5160 - mean_squared_error: 82.5160 - val_loss: 95.8693 - val_mean_squared_error: 95.8693\n",
      "Epoch 196/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 82.5147 - mean_squared_error: 82.5147 - val_loss: 95.8528 - val_mean_squared_error: 95.8528\n",
      "Epoch 197/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 82.5213 - mean_squared_error: 82.5213 - val_loss: 95.8629 - val_mean_squared_error: 95.8629\n",
      "Epoch 198/300\n",
      "430/430 [==============================] - 0s 108us/step - loss: 82.5174 - mean_squared_error: 82.5174 - val_loss: 95.8478 - val_mean_squared_error: 95.8478\n",
      "Epoch 199/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.5177 - mean_squared_error: 82.5177 - val_loss: 95.8571 - val_mean_squared_error: 95.8571\n",
      "Epoch 200/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5232 - mean_squared_error: 82.5232 - val_loss: 95.8426 - val_mean_squared_error: 95.8426\n",
      "Epoch 201/300\n",
      "430/430 [==============================] - 0s 122us/step - loss: 82.5177 - mean_squared_error: 82.5177 - val_loss: 95.8285 - val_mean_squared_error: 95.8285\n",
      "Epoch 202/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.5207 - mean_squared_error: 82.5207 - val_loss: 95.8561 - val_mean_squared_error: 95.8561\n",
      "Epoch 203/300\n",
      "430/430 [==============================] - 0s 120us/step - loss: 82.5244 - mean_squared_error: 82.5244 - val_loss: 95.8072 - val_mean_squared_error: 95.8072\n",
      "Epoch 204/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5179 - mean_squared_error: 82.5179 - val_loss: 95.8109 - val_mean_squared_error: 95.8109\n",
      "Epoch 205/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.5179 - mean_squared_error: 82.5179 - val_loss: 95.8070 - val_mean_squared_error: 95.8070\n",
      "Epoch 206/300\n",
      "430/430 [==============================] - 0s 107us/step - loss: 82.5221 - mean_squared_error: 82.5221 - val_loss: 95.8099 - val_mean_squared_error: 95.8099\n",
      "Epoch 207/300\n",
      "430/430 [==============================] - 0s 130us/step - loss: 82.5174 - mean_squared_error: 82.5174 - val_loss: 95.8088 - val_mean_squared_error: 95.8088\n",
      "Epoch 208/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 82.5117 - mean_squared_error: 82.5117 - val_loss: 95.7940 - val_mean_squared_error: 95.7940\n",
      "Epoch 209/300\n",
      "430/430 [==============================] - 0s 120us/step - loss: 82.5106 - mean_squared_error: 82.5106 - val_loss: 95.7888 - val_mean_squared_error: 95.7888\n",
      "Epoch 210/300\n",
      "430/430 [==============================] - 0s 111us/step - loss: 82.5208 - mean_squared_error: 82.5208 - val_loss: 95.8018 - val_mean_squared_error: 95.8018\n",
      "Epoch 211/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 82.5195 - mean_squared_error: 82.5195 - val_loss: 95.7614 - val_mean_squared_error: 95.7614\n",
      "Epoch 212/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5172 - mean_squared_error: 82.5172 - val_loss: 95.7680 - val_mean_squared_error: 95.7680\n",
      "Epoch 213/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5215 - mean_squared_error: 82.5215 - val_loss: 95.7828 - val_mean_squared_error: 95.7828\n",
      "Epoch 214/300\n",
      "430/430 [==============================] - 0s 136us/step - loss: 82.5175 - mean_squared_error: 82.5175 - val_loss: 95.7606 - val_mean_squared_error: 95.7606\n",
      "Epoch 215/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 82.5165 - mean_squared_error: 82.5165 - val_loss: 95.7904 - val_mean_squared_error: 95.7904\n",
      "Epoch 216/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5161 - mean_squared_error: 82.5161 - val_loss: 95.7506 - val_mean_squared_error: 95.7506\n",
      "Epoch 217/300\n",
      "430/430 [==============================] - 0s 118us/step - loss: 82.5118 - mean_squared_error: 82.5118 - val_loss: 95.7404 - val_mean_squared_error: 95.7404\n",
      "Epoch 218/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.5085 - mean_squared_error: 82.5085 - val_loss: 95.7479 - val_mean_squared_error: 95.7479\n",
      "Epoch 219/300\n",
      "430/430 [==============================] - 0s 166us/step - loss: 82.5152 - mean_squared_error: 82.5152 - val_loss: 95.7647 - val_mean_squared_error: 95.7647\n",
      "Epoch 220/300\n",
      "430/430 [==============================] - 0s 122us/step - loss: 82.5104 - mean_squared_error: 82.5104 - val_loss: 95.7655 - val_mean_squared_error: 95.7655\n",
      "Epoch 221/300\n",
      "430/430 [==============================] - 0s 147us/step - loss: 82.5263 - mean_squared_error: 82.5263 - val_loss: 95.8041 - val_mean_squared_error: 95.8041\n",
      "Epoch 222/300\n",
      "430/430 [==============================] - 0s 123us/step - loss: 82.5152 - mean_squared_error: 82.5152 - val_loss: 95.7502 - val_mean_squared_error: 95.7502\n",
      "Epoch 223/300\n",
      "430/430 [==============================] - 0s 118us/step - loss: 82.5081 - mean_squared_error: 82.5081 - val_loss: 95.7641 - val_mean_squared_error: 95.7641\n",
      "Epoch 224/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5131 - mean_squared_error: 82.5131 - val_loss: 95.7558 - val_mean_squared_error: 95.7558\n",
      "Epoch 225/300\n",
      "430/430 [==============================] - 0s 120us/step - loss: 82.5090 - mean_squared_error: 82.5090 - val_loss: 95.7625 - val_mean_squared_error: 95.7625\n",
      "Epoch 226/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 82.5170 - mean_squared_error: 82.5170 - val_loss: 95.7480 - val_mean_squared_error: 95.7480\n",
      "Epoch 227/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5095 - mean_squared_error: 82.5095 - val_loss: 95.7427 - val_mean_squared_error: 95.7427\n",
      "Epoch 228/300\n",
      "430/430 [==============================] - 0s 129us/step - loss: 82.5100 - mean_squared_error: 82.5100 - val_loss: 95.7629 - val_mean_squared_error: 95.7629\n",
      "Epoch 229/300\n",
      "430/430 [==============================] - 0s 107us/step - loss: 82.5284 - mean_squared_error: 82.5284 - val_loss: 95.7227 - val_mean_squared_error: 95.7227\n",
      "Epoch 230/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5101 - mean_squared_error: 82.5101 - val_loss: 95.7619 - val_mean_squared_error: 95.7619\n",
      "Epoch 231/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5325 - mean_squared_error: 82.5325 - val_loss: 95.7913 - val_mean_squared_error: 95.7913\n",
      "Epoch 232/300\n",
      "430/430 [==============================] - 0s 105us/step - loss: 82.5077 - mean_squared_error: 82.5077 - val_loss: 95.7532 - val_mean_squared_error: 95.7532\n",
      "Epoch 233/300\n",
      "430/430 [==============================] - 0s 105us/step - loss: 82.5111 - mean_squared_error: 82.5111 - val_loss: 95.7571 - val_mean_squared_error: 95.7571\n",
      "Epoch 234/300\n",
      "430/430 [==============================] - 0s 107us/step - loss: 82.5102 - mean_squared_error: 82.5102 - val_loss: 95.7545 - val_mean_squared_error: 95.7545\n",
      "Epoch 235/300\n",
      "430/430 [==============================] - 0s 134us/step - loss: 82.5087 - mean_squared_error: 82.5087 - val_loss: 95.7420 - val_mean_squared_error: 95.7420\n",
      "Epoch 236/300\n",
      "430/430 [==============================] - 0s 148us/step - loss: 82.5123 - mean_squared_error: 82.5123 - val_loss: 95.7388 - val_mean_squared_error: 95.7388\n",
      "Epoch 237/300\n",
      "430/430 [==============================] - 0s 179us/step - loss: 82.5082 - mean_squared_error: 82.5082 - val_loss: 95.7565 - val_mean_squared_error: 95.7565\n",
      "Epoch 238/300\n",
      "430/430 [==============================] - 0s 182us/step - loss: 82.5093 - mean_squared_error: 82.5093 - val_loss: 95.7246 - val_mean_squared_error: 95.7246\n",
      "Epoch 239/300\n",
      "430/430 [==============================] - 0s 170us/step - loss: 82.5107 - mean_squared_error: 82.5107 - val_loss: 95.7201 - val_mean_squared_error: 95.7201\n",
      "Epoch 240/300\n",
      "430/430 [==============================] - 0s 126us/step - loss: 82.5077 - mean_squared_error: 82.5077 - val_loss: 95.7284 - val_mean_squared_error: 95.7284\n",
      "Epoch 241/300\n",
      "430/430 [==============================] - 0s 169us/step - loss: 82.5070 - mean_squared_error: 82.5070 - val_loss: 95.7275 - val_mean_squared_error: 95.7275\n",
      "Epoch 242/300\n",
      "430/430 [==============================] - 0s 135us/step - loss: 82.5084 - mean_squared_error: 82.5084 - val_loss: 95.7202 - val_mean_squared_error: 95.7202\n",
      "Epoch 243/300\n",
      "430/430 [==============================] - 0s 140us/step - loss: 82.5080 - mean_squared_error: 82.5080 - val_loss: 95.7285 - val_mean_squared_error: 95.7285\n",
      "Epoch 244/300\n",
      "430/430 [==============================] - 0s 139us/step - loss: 82.5083 - mean_squared_error: 82.5083 - val_loss: 95.7168 - val_mean_squared_error: 95.7168\n",
      "Epoch 245/300\n",
      "430/430 [==============================] - 0s 145us/step - loss: 82.5080 - mean_squared_error: 82.5080 - val_loss: 95.7141 - val_mean_squared_error: 95.7141\n",
      "Epoch 246/300\n",
      "430/430 [==============================] - 0s 137us/step - loss: 82.5153 - mean_squared_error: 82.5153 - val_loss: 95.7564 - val_mean_squared_error: 95.7564\n",
      "Epoch 247/300\n",
      "430/430 [==============================] - 0s 140us/step - loss: 82.5072 - mean_squared_error: 82.5072 - val_loss: 95.7280 - val_mean_squared_error: 95.7280\n",
      "Epoch 248/300\n",
      "430/430 [==============================] - 0s 138us/step - loss: 82.5110 - mean_squared_error: 82.5110 - val_loss: 95.7307 - val_mean_squared_error: 95.7307\n",
      "Epoch 249/300\n",
      "430/430 [==============================] - 0s 133us/step - loss: 82.5103 - mean_squared_error: 82.5103 - val_loss: 95.7473 - val_mean_squared_error: 95.7473\n",
      "Epoch 250/300\n",
      "430/430 [==============================] - 0s 126us/step - loss: 82.5083 - mean_squared_error: 82.5083 - val_loss: 95.7539 - val_mean_squared_error: 95.7539\n",
      "Epoch 251/300\n",
      "430/430 [==============================] - 0s 164us/step - loss: 82.5071 - mean_squared_error: 82.5071 - val_loss: 95.7036 - val_mean_squared_error: 95.7036\n",
      "Epoch 252/300\n",
      "430/430 [==============================] - 0s 169us/step - loss: 82.5075 - mean_squared_error: 82.5075 - val_loss: 95.6986 - val_mean_squared_error: 95.6986\n",
      "Epoch 253/300\n",
      "430/430 [==============================] - 0s 159us/step - loss: 82.5084 - mean_squared_error: 82.5084 - val_loss: 95.7172 - val_mean_squared_error: 95.7172\n",
      "Epoch 254/300\n",
      "430/430 [==============================] - 0s 140us/step - loss: 82.5269 - mean_squared_error: 82.5269 - val_loss: 95.7419 - val_mean_squared_error: 95.7419\n",
      "Epoch 255/300\n",
      "430/430 [==============================] - 0s 139us/step - loss: 82.5058 - mean_squared_error: 82.5058 - val_loss: 95.7250 - val_mean_squared_error: 95.7250\n",
      "Epoch 256/300\n",
      "430/430 [==============================] - 0s 139us/step - loss: 82.5081 - mean_squared_error: 82.5081 - val_loss: 95.7239 - val_mean_squared_error: 95.7239\n",
      "Epoch 257/300\n",
      "430/430 [==============================] - 0s 179us/step - loss: 82.5087 - mean_squared_error: 82.5087 - val_loss: 95.6989 - val_mean_squared_error: 95.6989\n",
      "Epoch 258/300\n",
      "430/430 [==============================] - 0s 146us/step - loss: 82.5063 - mean_squared_error: 82.5063 - val_loss: 95.7055 - val_mean_squared_error: 95.7055\n",
      "Epoch 259/300\n",
      "430/430 [==============================] - 0s 145us/step - loss: 82.5054 - mean_squared_error: 82.5054 - val_loss: 95.6952 - val_mean_squared_error: 95.6952\n",
      "Epoch 260/300\n",
      "430/430 [==============================] - 0s 151us/step - loss: 82.5040 - mean_squared_error: 82.5040 - val_loss: 95.7029 - val_mean_squared_error: 95.7029\n",
      "Epoch 261/300\n",
      "430/430 [==============================] - 0s 127us/step - loss: 82.5066 - mean_squared_error: 82.5066 - val_loss: 95.7074 - val_mean_squared_error: 95.7074\n",
      "Epoch 262/300\n",
      "430/430 [==============================] - 0s 127us/step - loss: 82.5082 - mean_squared_error: 82.5082 - val_loss: 95.7252 - val_mean_squared_error: 95.7252\n",
      "Epoch 263/300\n",
      "430/430 [==============================] - 0s 125us/step - loss: 82.5101 - mean_squared_error: 82.5101 - val_loss: 95.6977 - val_mean_squared_error: 95.6977\n",
      "Epoch 264/300\n",
      "430/430 [==============================] - 0s 133us/step - loss: 82.5055 - mean_squared_error: 82.5055 - val_loss: 95.7169 - val_mean_squared_error: 95.7169\n",
      "Epoch 265/300\n",
      "430/430 [==============================] - 0s 127us/step - loss: 82.5127 - mean_squared_error: 82.5127 - val_loss: 95.7074 - val_mean_squared_error: 95.7074\n",
      "Epoch 266/300\n",
      "430/430 [==============================] - 0s 137us/step - loss: 82.5239 - mean_squared_error: 82.5239 - val_loss: 95.6675 - val_mean_squared_error: 95.6675\n",
      "Epoch 267/300\n",
      "430/430 [==============================] - 0s 130us/step - loss: 82.5107 - mean_squared_error: 82.5107 - val_loss: 95.7071 - val_mean_squared_error: 95.7071\n",
      "Epoch 268/300\n",
      "430/430 [==============================] - 0s 148us/step - loss: 82.5070 - mean_squared_error: 82.5070 - val_loss: 95.7408 - val_mean_squared_error: 95.7408\n",
      "Epoch 269/300\n",
      "430/430 [==============================] - 0s 120us/step - loss: 82.5151 - mean_squared_error: 82.5151 - val_loss: 95.6778 - val_mean_squared_error: 95.6778\n",
      "Epoch 270/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5143 - mean_squared_error: 82.5143 - val_loss: 95.6991 - val_mean_squared_error: 95.6991\n",
      "Epoch 271/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.5094 - mean_squared_error: 82.5094 - val_loss: 95.7052 - val_mean_squared_error: 95.7052\n",
      "Epoch 272/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 82.5063 - mean_squared_error: 82.5063 - val_loss: 95.6955 - val_mean_squared_error: 95.6955\n",
      "Epoch 273/300\n",
      "430/430 [==============================] - 0s 126us/step - loss: 82.5083 - mean_squared_error: 82.5083 - val_loss: 95.7147 - val_mean_squared_error: 95.7147\n",
      "Epoch 274/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.5098 - mean_squared_error: 82.5098 - val_loss: 95.6928 - val_mean_squared_error: 95.6928\n",
      "Epoch 275/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 82.5094 - mean_squared_error: 82.5094 - val_loss: 95.7264 - val_mean_squared_error: 95.7264\n",
      "Epoch 276/300\n",
      "430/430 [==============================] - 0s 108us/step - loss: 82.5050 - mean_squared_error: 82.5050 - val_loss: 95.6923 - val_mean_squared_error: 95.6923\n",
      "Epoch 277/300\n",
      "430/430 [==============================] - 0s 108us/step - loss: 82.5152 - mean_squared_error: 82.5152 - val_loss: 95.6738 - val_mean_squared_error: 95.6738\n",
      "Epoch 278/300\n",
      "430/430 [==============================] - 0s 121us/step - loss: 82.5063 - mean_squared_error: 82.5063 - val_loss: 95.6823 - val_mean_squared_error: 95.6823\n",
      "Epoch 279/300\n",
      "430/430 [==============================] - 0s 142us/step - loss: 82.5082 - mean_squared_error: 82.5082 - val_loss: 95.7046 - val_mean_squared_error: 95.7046\n",
      "Epoch 280/300\n",
      "430/430 [==============================] - 0s 117us/step - loss: 82.5041 - mean_squared_error: 82.5041 - val_loss: 95.6907 - val_mean_squared_error: 95.6907\n",
      "Epoch 281/300\n",
      "430/430 [==============================] - 0s 119us/step - loss: 82.5082 - mean_squared_error: 82.5082 - val_loss: 95.6935 - val_mean_squared_error: 95.6935\n",
      "Epoch 282/300\n",
      "430/430 [==============================] - 0s 126us/step - loss: 82.5061 - mean_squared_error: 82.5061 - val_loss: 95.6767 - val_mean_squared_error: 95.6767\n",
      "Epoch 283/300\n",
      "430/430 [==============================] - 0s 122us/step - loss: 82.5085 - mean_squared_error: 82.5085 - val_loss: 95.7054 - val_mean_squared_error: 95.7054\n",
      "Epoch 284/300\n",
      "430/430 [==============================] - 0s 188us/step - loss: 82.5066 - mean_squared_error: 82.5066 - val_loss: 95.6997 - val_mean_squared_error: 95.6997\n",
      "Epoch 285/300\n",
      "430/430 [==============================] - 0s 150us/step - loss: 82.5066 - mean_squared_error: 82.5066 - val_loss: 95.6777 - val_mean_squared_error: 95.6777\n",
      "Epoch 286/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 82.5077 - mean_squared_error: 82.5077 - val_loss: 95.7069 - val_mean_squared_error: 95.7069\n",
      "Epoch 287/300\n",
      "430/430 [==============================] - 0s 109us/step - loss: 82.5160 - mean_squared_error: 82.5160 - val_loss: 95.6617 - val_mean_squared_error: 95.6617\n",
      "Epoch 288/300\n",
      "430/430 [==============================] - 0s 145us/step - loss: 82.5125 - mean_squared_error: 82.5125 - val_loss: 95.6672 - val_mean_squared_error: 95.6672\n",
      "Epoch 289/300\n",
      "430/430 [==============================] - 0s 142us/step - loss: 82.5062 - mean_squared_error: 82.5062 - val_loss: 95.6947 - val_mean_squared_error: 95.6947\n",
      "Epoch 290/300\n",
      "430/430 [==============================] - 0s 145us/step - loss: 82.5165 - mean_squared_error: 82.5165 - val_loss: 95.6941 - val_mean_squared_error: 95.6941\n",
      "Epoch 291/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 82.5102 - mean_squared_error: 82.5102 - val_loss: 95.6881 - val_mean_squared_error: 95.6881\n",
      "Epoch 292/300\n",
      "430/430 [==============================] - 0s 115us/step - loss: 82.5048 - mean_squared_error: 82.5048 - val_loss: 95.6915 - val_mean_squared_error: 95.6915\n",
      "Epoch 293/300\n",
      "430/430 [==============================] - 0s 110us/step - loss: 82.5052 - mean_squared_error: 82.5052 - val_loss: 95.6680 - val_mean_squared_error: 95.6680\n",
      "Epoch 294/300\n",
      "430/430 [==============================] - 0s 114us/step - loss: 82.5064 - mean_squared_error: 82.5064 - val_loss: 95.6815 - val_mean_squared_error: 95.6815\n",
      "Epoch 295/300\n",
      "430/430 [==============================] - 0s 135us/step - loss: 82.5081 - mean_squared_error: 82.5081 - val_loss: 95.6548 - val_mean_squared_error: 95.6548\n",
      "Epoch 296/300\n",
      "430/430 [==============================] - 0s 116us/step - loss: 82.5042 - mean_squared_error: 82.5042 - val_loss: 95.6678 - val_mean_squared_error: 95.6678\n",
      "Epoch 297/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5082 - mean_squared_error: 82.5082 - val_loss: 95.6568 - val_mean_squared_error: 95.6568\n",
      "Epoch 298/300\n",
      "430/430 [==============================] - 0s 112us/step - loss: 82.5039 - mean_squared_error: 82.5039 - val_loss: 95.6800 - val_mean_squared_error: 95.6800\n",
      "Epoch 299/300\n",
      "430/430 [==============================] - 0s 119us/step - loss: 82.5067 - mean_squared_error: 82.5067 - val_loss: 95.6561 - val_mean_squared_error: 95.6561\n",
      "Epoch 300/300\n",
      "430/430 [==============================] - 0s 113us/step - loss: 82.5036 - mean_squared_error: 82.5036 - val_loss: 95.7018 - val_mean_squared_error: 95.7018\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "training_model = model.fit(training_set[FEATURES].values, \n",
    "          training_set[LABEL].values, \n",
    "          epochs=epochs_value,\n",
    "          batch_size=batch_size_value,\n",
    "          validation_data=(test_set[FEATURES].values, test_set[LABEL].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwoFuZpaJ/wfe5RC4P81hMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot MSE, compare with initial plot\n",
    "plt.plot(training_model.history['mean_squared_error'][-50:], 'r+', label='training mean_squared_error')\n",
    "plt.plot(training_model.history['val_mean_squared_error'][-50:], 'y.', label='evaluation mean_squared_error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Mean Squared Error over Epochs')\n",
    "plt.show()\n",
    "\n",
    "#new model(300 epochs):\n",
    "#training MSE: 78.2353, evaluation MSE: 92.6427\n",
    "\n",
    "#original model:\n",
    "#training MSE: 81.7415, evaluation MSE: 94.5644\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "Total parameters = 111\n"
     ]
    }
   ],
   "source": [
    "#calc number of new parameters\n",
    "print(model.summary(),'\\n')\n",
    "print('Total parameters = 111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the impact of changing epoch values from 100 to 300? \n",
      "\n",
      "The training and evaulation MSE both decreased slightly when using 300 epochs instead of 100.\n",
      "The plot above shows the change and the decreasing trend as epochs increase.\n"
     ]
    }
   ],
   "source": [
    "print('What is the impact of changing epoch values from 100 to 300?','\\n')\n",
    "\n",
    "print('The training and evaulation MSE both decreased slightly when using 300 epochs instead of 100.')\n",
    "print('The plot above shows the change and the decreasing trend as epochs increase.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
